{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import events and time till each event\n",
    "cohort = pd.read_excel(\"kihd_time_to_event.xlsx\")\n",
    "# Add a column with time in years (it will be used for plots)\n",
    "cohort['time, years'] = (cohort['time']/365.25).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Splitting into training and test parts with stratification\n",
    "# ---------------------------------------------------------\n",
    "def train_test_split(outcomes, train_percent = 0.8, event = 'event', time = 'time'):\n",
    "    '''\n",
    "    Split time-to-event data into training and test parts with stratification\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "     outcomes: pd.DataFrame\n",
    "         time-to-event data with columns that contain events and times \n",
    "     train_percent: float, optional\n",
    "         percentage of training examples in splitting\n",
    "     event: string, optional\n",
    "         a string to define the column with events in the data frame\n",
    "     time: string, optional\n",
    "         a string to define the column with time in the data frame\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    training_indices: list\n",
    "        a list with indices of training examples\n",
    "    test_indices: list\n",
    "        a list with indices of test examples\n",
    "    '''\n",
    "    \n",
    "    if event not in outcomes.columns or time not in outcomes.columns:\n",
    "        raise ValueError(\"'event' and/or 'time' columns are not found. Specify names of these columns in the function arguments\")\n",
    "\n",
    "    outcomes = outcomes.loc[:, [event, time]].copy()\n",
    "    outcomes = outcomes.rename(columns={event: 'event', time: 'time'})\n",
    "    \n",
    "    outcomes.time = outcomes.time.astype(str)\n",
    "    outcomes.event = outcomes.event.astype(str)\n",
    "    \n",
    "    training_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for time in outcomes.time.unique():\n",
    "        for event in outcomes.event.unique():\n",
    "            subsample = outcomes.loc[ (outcomes.time == time) & (outcomes.event == event) ]\n",
    "\n",
    "            if subsample.shape[0] > 0:\n",
    "                train_index = list(subsample.sample(frac = train_percent, replace = False).index)\n",
    "                train_index.sort()\n",
    "                test_index = list(set(subsample.index) - set(train_index))\n",
    "\n",
    "                training_indices.extend(train_index)\n",
    "                test_indices.extend(test_index)\n",
    "\n",
    "    training_indices.sort()\n",
    "    test_indices.sort()\n",
    "    \n",
    "    return training_indices, test_indices\n",
    "\n",
    "# An example of using the 'train_test_split' function with a default 0.8 sptitting ratio \n",
    "# training_indices, test_indices = train_test_split(cohort, time = 'time, years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out predictors with more than 5.0% of missing values ...\n",
      "Dataset size: 2682x658\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import and prepare data:\n",
    "# -------------------------------------------------------\n",
    "# 1 - A sample with seven traditional risk factors\n",
    "# -------------------------------------------------------\n",
    "kihd_preselected_predictors = pd.read_excel(\"kihd_7_inputs_na.xlsx\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2 - A sample with hundreds of predictors\n",
    "# -------------------------------------------------------\n",
    "kihd_predictors = pd.read_excel(\"KIHD_phenotypes.xlsx\")\n",
    "\n",
    "# Preprocessing of the second sample with many predictors\n",
    "# Remove variables (columns) containing more than 5% of missing values\n",
    "gaps = 0.05\n",
    "threshold_columns = kihd_predictors.shape[0]-round(gaps*kihd_predictors.shape[0])\n",
    "kihd_predictors = kihd_predictors.dropna(axis=1, thresh=threshold_columns)\n",
    "\n",
    "# Turn the categorical variables into dummies\n",
    "categorical_variables=['au0136','au0153','ek0115','ek0119','ka0118','mi0205','mi0207','mi0208','mi0209',\n",
    "                       'mi0210','mi0211','mi0212','mi0213','mi0214','v0145','v0146','v0157','v0158','v0161',\n",
    "                       'v0172','v0247','v0248','v0665','v0721','v0724','u1307']\n",
    "\n",
    "for col in categorical_variables:\n",
    "    if col in kihd_predictors.columns:\n",
    "        new_dummies=pd.get_dummies(kihd_predictors[col], dummy_na=False)\n",
    "        my_list = new_dummies.columns.values\n",
    "        string = col+\"_\"\n",
    "        my_new_list = [string + str(x) for x in my_list]\n",
    "        new_dummies.columns = my_new_list\n",
    "        kihd_predictors = kihd_predictors.drop(col, axis=1)       \n",
    "        kihd_predictors = kihd_predictors.join(new_dummies)\n",
    "\n",
    "print(\"Filter out predictors with more than {}% of missing values ...\".format(gaps*100))\n",
    "print(\"Dataset size: {rows}x{cols}\".format(rows = kihd_predictors.shape[0], cols = kihd_predictors.shape[1]))\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________\n",
    "For the sample with pre-selected predictors:\n",
    "____________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Function:\n",
    "# Train an imputer with the MICE algorithm to fill gaps in training and test data\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def filling_gaps_small_data(train_data, test_data):\n",
    "    '''\n",
    "    Fill gaps in training and test data using MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: pd.DataFrame\n",
    "         predictors with gaps to train an imputer \n",
    "    test_data: pd.DataFrame\n",
    "         predictors with gaps to apply an imputer \n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    train_data_filled: pd.DataFrame\n",
    "        training data with filled gaps\n",
    "    test_data_filled: pd.DataFrame\n",
    "        test data with filled gaps\n",
    "    '''\n",
    "\n",
    "    # Create kernel \n",
    "    np.random.seed()\n",
    "\n",
    "    # Define parameters of the MICE algorithm from the miceforest package\n",
    "    mice_kernel = mf.KernelDataSet(\n",
    "    train_data,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=True,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "\n",
    "    # Run 10 iterations of the MICE algorithm\n",
    "    mice_kernel.mice(10, n_jobs=2, max_depth = 3, n_estimators=100, oob_score=True, bootstrap=True)\n",
    "\n",
    "    # Return a training dataset filled\n",
    "    train_filled = mice_kernel.complete_data()\n",
    "    # Apply the trained imputer to a test dataset\n",
    "    test_filled = mice_kernel.impute_new_data(new_data=test_data)\n",
    "    # Return a test dataset filled\n",
    "    test_filled = test_filled.complete_data()\n",
    "    \n",
    "    return train_filled, test_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory splitting_7_predictors\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Splitting into training, test, training_valid and validation parts; \n",
    "# Filling gaps in each split\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "N_runs = 1\n",
    "\n",
    "# A directory to be created for the first (selected predictors) sample\n",
    "folder1 = \"splitting_7_predictors\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder1)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder1)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder1)\n",
    "\n",
    "# Split data and save in files\n",
    "for r in range(N_runs):\n",
    "    # Split into training and test parts\n",
    "    training_indices, test_indices = train_test_split(cohort, time = 'time, years')\n",
    "    \n",
    "    # Fill gaps in training and test data\n",
    "    kihd_preselected_predictors_training, kihd_preselected_predictors_test = filling_gaps_small_data(\n",
    "                                                                                kihd_preselected_predictors.loc[training_indices],\n",
    "                                                                                kihd_preselected_predictors.loc[test_indices]\n",
    "                                                                                                    )\n",
    "    # For validation: Split into training and validation parts\n",
    "    training_indices_on_validation, validation_indices = train_test_split(\n",
    "                                                                    cohort.loc[training_indices],\n",
    "                                                                    time = 'time, years'\n",
    "                                                                         )\n",
    "    \n",
    "    # Save training, test, training_valid and validation parts for the selected predictors\n",
    "    kihd_preselected_predictors_training.to_excel(folder1 + \"/training_{}.xlsx\".format(r))\n",
    "    kihd_preselected_predictors_test.to_excel(folder1 + \"/test_{}.xlsx\".format(r))\n",
    "    kihd_preselected_predictors_training.loc[training_indices_on_validation].to_excel(folder1 + \"/training_valid_{}.xlsx\".format(r))\n",
    "    kihd_preselected_predictors_training.loc[validation_indices].to_excel(folder1 + \"/validation_{}.xlsx\".format(r))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________\n",
    "For the sample with many predictors:\n",
    "____________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Function:\n",
    "# Train an imputer with the MICE algorithm to fill gaps in training and test data\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def filling_gaps_big_data(train_data, test_data):\n",
    "    '''\n",
    "    Fill gaps in training and test data using MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: pd.DataFrame\n",
    "         predictors with gaps to train an imputer \n",
    "    test_data: pd.DataFrame\n",
    "         predictors with gaps to apply an imputer \n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    train_filled: pd.DataFrame\n",
    "        training data with filled gaps\n",
    "    test_filled: pd.DataFrame\n",
    "        test data with filled gaps\n",
    "    '''\n",
    "\n",
    "    # In this function, an imputer first is trained to fill gaps in the training data.\n",
    "    # Then, training samples without gaps are combined with test sampes with gaps\n",
    "    # and an inputer is trained again to fill gaps in the test data.\n",
    "    # This is done in this way because test examples have missing values in variables \n",
    "    # that have no gaps in the training data, therefore, the MICE imputer cannot fill\n",
    "    # them after training on the training data. \n",
    "    # This procedure immitates the real world scenario, when the model is first trained\n",
    "    # on some data, then other unseen data come for tests. \n",
    "    \n",
    "    # Create kernel \n",
    "    np.random.seed()\n",
    "\n",
    "    # Define parameters of the MICE algorithm from the miceforest package\n",
    "    mice_kernel = mf.KernelDataSet(\n",
    "    train_data,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=True,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "\n",
    "    # Run 10 iterations of the MICE algorithm\n",
    "    mice_kernel.mice(10, n_jobs=10, max_depth = 5, n_estimators=100, oob_score=True, bootstrap=True)\n",
    "\n",
    "    # Return a training dataset filled\n",
    "    train_filled = mice_kernel.complete_data()\n",
    "\n",
    "    # Train and test joint sample\n",
    "    test_starts = train_filled.shape[0]\n",
    "    all_samples = pd.concat([train_filled, test_data])\n",
    "    \n",
    "    # Create kernel for all samples\n",
    "    np.random.seed()\n",
    "\n",
    "    mice_kernel_test = mf.KernelDataSet(\n",
    "    all_samples,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=False,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "    \n",
    "    # Run the MICE algorithm for 10 iterations (to fill gaps in test samples)\n",
    "    mice_kernel_test.mice(10, n_jobs=10, max_depth = 5, n_estimators=100, oob_score=True, bootstrap=True)\n",
    "    \n",
    "    # Fill gaps in samples (gaps are in test samples)\n",
    "    all_samples_filled = mice_kernel_test.complete_data()\n",
    "\n",
    "    # Return filled test samples\n",
    "    test_filled = all_samples_filled.iloc[test_starts:,]\n",
    "    \n",
    "    \n",
    "    return train_filled, test_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory splitting_658_predictors failed (already exists?)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Splitting into training, test, training_valid and validation parts; \n",
    "# Filling gaps in each split\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "N_runs = 10\n",
    "\n",
    "# A directory to be created for the first (selected predictors) sample\n",
    "folder2 = \"splitting_{}_predictors\".format(kihd_predictors.shape[1])\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder2)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder2)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder2)\n",
    "\n",
    "# Split data and save in files\n",
    "for r in range(N_runs):\n",
    "    # Split into training and test parts\n",
    "    training_indices, test_indices = train_test_split(cohort, time = 'time, years')\n",
    "    \n",
    "    # Fill gaps in training and test data\n",
    "    kihd_training, kihd_test = filling_gaps_big_data(\n",
    "                                                    kihd_predictors.loc[training_indices],\n",
    "                                                    kihd_predictors.loc[test_indices]\n",
    "                                                    )\n",
    "    # For validation: Split into training and validation parts\n",
    "    training_indices_on_validation, validation_indices = train_test_split(\n",
    "                                                                    cohort.loc[training_indices],\n",
    "                                                                    time = 'time, years'\n",
    "                                                                         )\n",
    "    \n",
    "    # Save training, test, training_valid and validation parts for the selected predictors\n",
    "    kihd_training.to_excel(folder2 + \"/training_{}.xlsx\".format(r))\n",
    "    kihd_test.to_excel(folder2 + \"/test_{}.xlsx\".format(r))\n",
    "    kihd_training.loc[training_indices_on_validation].to_excel(folder2 + \"/training_valid_{}.xlsx\".format(r))\n",
    "    kihd_training.loc[validation_indices].to_excel(folder2 + \"/validation_{}.xlsx\".format(r))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________\n",
    "Check (visually) CIFs of all subjects, training and test data\n",
    "_____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "# Load the rpy2 IPython extension into the notebook to use R with a magic command: %%R\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# :::::::::\n",
    "# R kernel\n",
    "# :::::::::\n",
    "\n",
    "install.packages(\"readxl\")\n",
    "install.packages(\"cmprsk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -w 600 -h 300\n",
    "# ----------------------------------------------------------------\n",
    "# Cumulative Incidence Functions (CIFs) for training and test data\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Load necessary packages\n",
    "library(\"readxl\")\n",
    "\n",
    "# Import the CumIncidence function from the file \n",
    "source(\"CumIncidence.R\")\n",
    "\n",
    "par(mar=c(1,1,1,1))\n",
    "\n",
    "path_to_training <- \"splitting_7_predictors/training_1.xlsx\" # Choose splitting to check\n",
    "path_to_test <- \"splitting_7_predictors/test_1.xlsx\" # Choose splitting to check\n",
    "\n",
    "cohort_test <- read_excel(path_to_test)\n",
    "\n",
    "cohort <- read_excel(\"kihd_time_to_event.xlsx\")\n",
    "cohort[\"sample\"] <- \"training\"\n",
    "cohort[unlist(cohort_test[,1])+1, \"sample\"] <- \"test\"\n",
    "\n",
    "# Add examples without splitting\n",
    "cohort_all <- cohort\n",
    "cohort_all['sample'] <- 'all subjects'\n",
    "cohort_all <- rbind(cohort_all, cohort)\n",
    "\n",
    "# !!! To save a plot in a file, uncomment the next line: \n",
    "# png(\"CIFs train test.png\", res = 200, width = 1500, height = 800,  units = 'px')\n",
    "\n",
    "# Compare CIFs in training and test parts to the whole cohort\n",
    "# Main parameters are times, events, groups (training/test/no splitting), code for censoring\n",
    "fit = CumIncidence(cohort_all$time, cohort_all$event, cohort_all$sample, cencode = 0, xlab = 'time', ylab = 'CIF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
