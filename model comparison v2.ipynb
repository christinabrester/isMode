{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "import plotly\n",
    "import os\n",
    "import miceforest as mf\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all samples from the file\n",
    "data_kihd = pd.read_excel('kihd_may_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scenario\n",
    "\n",
    "scenario = 0 # scenario = 1\n",
    "\n",
    "# if scenario == 0, then competing risks are removed\n",
    "# if scenario == 1, then competing risks are treated as non-cases\n",
    "\n",
    "if scenario == 0:\n",
    "    folder_prefix = 'no_ncvd'\n",
    "else:\n",
    "    folder_prefix = 'ncvd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 994)\n",
      "KIHD with genes only: (2682, 96)\n",
      "KIHD with phenotypes only: (2682, 977)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Keep the original data in 'data_kihd' and use its copy 'data_kihd_preprocessed' instead\n",
    "# -----------------------------------------\n",
    "data_kihd_preprocessed = data_kihd.copy()\n",
    "\n",
    "# Drop two variables (dates of visits)\n",
    "#data_kihd_preprocessed = data_kihd_preprocessed.drop(['tpvm2', 'tpnr2'], axis = 1)\n",
    "\n",
    "# Correct the zero-level for the following variables:\n",
    "wrong_zero = ['v0563', 'v0565', 'v0567', 'v0569', 'v0571', 'v0573', 'v0575', 'v0577', 'v0579', 'v0607', 'v0609', 'v0613',\n",
    "              'v0621', 'v0623', 'v0625', 'v0627', 'v0629', 'v0631', 'v0633', 'v0635', 'v0637', 'v0639', 'v0643', 'v0645', \n",
    "              'v0647', 'v0649', 'v0651', 'v0653']\n",
    "# Zeros are at the wrong end of the scale\n",
    "# Change zeros to (max+1)\n",
    "for col in wrong_zero:\n",
    "    data_kihd_preprocessed.loc[:, col] = [np.max(data_kihd_preprocessed.loc[:, col]) + 1 if value == 0.0 else value for value in data_kihd_preprocessed.loc[:, col]]\n",
    "\n",
    "print(data_kihd_preprocessed.shape)\n",
    "# -----------------------------------------\n",
    "# Turn the categorical variables indo dummies\n",
    "# -----------------------------------------\n",
    "categorical_variables=['au0136','au0153','ek0115','ek0119','ka0118','mi0205','mi0207','mi0208','mi0209',\n",
    "                       'mi0210','mi0211','mi0212','mi0213','mi0214','v0145','v0146','v0157','v0158','v0161',\n",
    "                       'v0172','v0247','v0248','v0665','v0721','v0724','u1307']\n",
    "\n",
    "for col in categorical_variables:\n",
    "    if col in data_kihd_preprocessed.columns:\n",
    "        new_dummies=pd.get_dummies(data_kihd_preprocessed[col], dummy_na=False)\n",
    "        my_list = new_dummies.columns.values\n",
    "        string = col+\"_\"\n",
    "        my_new_list = [string + str(x) for x in my_list]\n",
    "        new_dummies.columns = my_new_list\n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.drop(col, axis=1)       \n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.join(new_dummies)\n",
    "                 \n",
    "# Outcomes\n",
    "kihd_outcomes = data_kihd_preprocessed.loc[:, ['tutknro', 'tpvm2', 'tpnr2', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d']]\n",
    "\n",
    "# Predictors\n",
    "kihd_predictors = data_kihd_preprocessed.drop(['tutknro', 'tpvm2', 'tpnr2', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d'], axis = 1)\n",
    "\n",
    "# Separate genes and phenotypes\n",
    "genes_start = list(kihd_predictors.columns.values).index('FEDER2HH'.lower())\n",
    "genes_end = list(kihd_predictors.columns.values).index('CATAETT'.lower())\n",
    "\n",
    "# Genes only\n",
    "kihd_genes = kihd_predictors.iloc[:, genes_start:(genes_end+1)].copy()\n",
    "print(\"KIHD with genes only: {}\".format(kihd_genes.shape))\n",
    "\n",
    "# Phenotypes\n",
    "kihd_phenotypes = kihd_predictors.drop(kihd_predictors.columns.values[genes_start:genes_end+1], axis = 1)\n",
    "print(\"KIHD with phenotypes only: {}\".format(kihd_phenotypes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out predictors with more than 5% of missing values ...\n",
      "Dataset size: 2682x746\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Remove predictors and subjects based on the number of missing values in 'kihd_phenotypes'\n",
    "# -----------------------------------------\n",
    "# Remove variables (columns) containing more than 5% of missing values\n",
    "threshold_columns = kihd_phenotypes.shape[0]-round(0.05*kihd_phenotypes.shape[0])\n",
    "kihd_phenotypes = kihd_phenotypes.dropna(axis=1, thresh=threshold_columns) \n",
    "\n",
    "print(\"Filter out predictors with more than 5% of missing values ...\")\n",
    "print(\"Dataset size: {rows}x{cols}\".format(rows = kihd_phenotypes.shape[0], cols = kihd_phenotypes.shape[1]))\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Remove subjects in genes and outcomes correspondingly\n",
    "kihd_genes = kihd_genes.loc[kihd_phenotypes.index, :]\n",
    "kihd_outcomes = kihd_outcomes.loc[kihd_phenotypes.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1861x746\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Handle competing risks\n",
    "# -----------------------------------------\n",
    "# Remove subjects died because of any non-cardiovascular reason within the prediction horizon\n",
    "prediction_horizon = 35*365.25\n",
    "\n",
    "if scenario == 0:\n",
    "    kihd_outcomes = kihd_outcomes.drop(kihd_outcomes[ (kihd_outcomes.loc[:, 'ncvd16'] == 1) & \n",
    "                                                     (kihd_outcomes.loc[:, 'ncvd16d'] <= prediction_horizon)].index, axis=0)\n",
    "    # Remove subjects in kihd_genes and kihd_phenotypes correspondingly\n",
    "    kihd_genes = kihd_genes.loc[kihd_outcomes.index, :]\n",
    "    kihd_phenotypes = kihd_phenotypes.loc[kihd_outcomes.index, :]\n",
    "\n",
    "    # Reset indices in all data frames after removing subjects \n",
    "    kihd_genes = kihd_genes.reset_index(drop=True)\n",
    "    kihd_outcomes = kihd_outcomes.reset_index(drop=True)\n",
    "    kihd_phenotypes = kihd_phenotypes.reset_index(drop=True)\n",
    "    \n",
    "    print(\"Dataset size: {rows}x{cols}\".format(rows = kihd_phenotypes.shape[0], cols = kihd_phenotypes.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline dataset\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an outcome variable\n",
    "outcome = 'cvd16'\n",
    "data_y = ((kihd_outcomes.loc[:, 'cvd16d'] <= prediction_horizon) & (kihd_outcomes.loc[:, 'cvd16'] == 1)).astype(\"int\").values.ravel()\n",
    "\n",
    "\n",
    "# Define the 'baseline' inputs\n",
    "data_x = kihd_phenotypes.loc[:, ['v0137', 'tup', 'mvp0224', 'bi0160', 'bi0171', 'diab', 'cvdfam']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and test parts\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory splitting_7_no_ncvd failed (already exists?)\n",
      "Creation of the directory splitting_746_no_ncvd failed (already exists?)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# A directory to be created for the baseline (selected predictors) sample\n",
    "folder1 = \"splitting_7_{}\".format(folder_prefix)\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder1)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder1)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder1)\n",
    "\n",
    "    \n",
    "# A directory to be created for the high-dim sample\n",
    "folder2 = \"splitting_746_{}\".format(folder_prefix)\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder2)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder2)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters of the experiment \n",
    "runs=50\n",
    "cv_splits=5\n",
    "\n",
    "\n",
    "def cv_splitting(cv_splits, data_x, data_y):\n",
    "    \n",
    "    splitting = StratifiedKFold(n_splits=cv_splits, random_state=None, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in splitting.split(data_x, data_y):\n",
    "\n",
    "        train_index_original = data_x.index[train_index]\n",
    "        test_index_original = data_x.index[test_index]\n",
    "\n",
    "        yield train_index_original, test_index_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Splitting data multiple times for cross-validation (upper loop)\n",
    "#\n",
    "for r in range(runs):\n",
    "    \n",
    "    generate_split = cv_splitting(cv_splits, data_x, data_y)\n",
    "    \n",
    "    for cv in range(cv_splits):\n",
    "        train_index, test_index = next(generate_split)\n",
    "        \n",
    "        # Save the current split in the folder:\n",
    "        # Baseline\n",
    "        train_data = data_x.loc[train_index].copy()\n",
    "        train_data['class'] = data_y[train_index]\n",
    "        \n",
    "        test_data = data_x.loc[test_index].copy()\n",
    "        test_data['class'] = data_y[test_index]\n",
    "        \n",
    "        train_data.to_excel(\"splitting_7_{}/train_data_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "        test_data.to_excel(\"splitting_7_{}/test_data_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "        \n",
    "        # Save the current split in the folder:\n",
    "        # High-dimesional\n",
    "        train_data = kihd_phenotypes.loc[train_index].copy()\n",
    "        train_data['class'] = data_y[train_index]\n",
    "        \n",
    "        test_data = kihd_phenotypes.loc[test_index].copy()\n",
    "        test_data['class'] = data_y[test_index]\n",
    "        \n",
    "        train_data.to_excel(\"splitting_746_{}/train_data_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "        test_data.to_excel(\"splitting_746_{}/test_data_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data imputation\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. baseline dataset (small)\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Function:\n",
    "# Train an imputer with the MICE algorithm to fill gaps in training and test data\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def filling_gaps_small_data(train_data, test_data):\n",
    "    '''\n",
    "    Fill gaps in training and test data using MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: pd.DataFrame\n",
    "         predictors with gaps to train an imputer \n",
    "    test_data: pd.DataFrame\n",
    "         predictors with gaps to apply an imputer \n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    train_data_filled: pd.DataFrame\n",
    "        training data with filled gaps\n",
    "    test_data_filled: pd.DataFrame\n",
    "        test data with filled gaps\n",
    "    '''\n",
    "\n",
    "    # Create kernel \n",
    "    np.random.seed()\n",
    "\n",
    "    # Define parameters of the MICE algorithm from the miceforest package\n",
    "    mice_kernel = mf.KernelDataSet(\n",
    "    train_data,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=True,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "\n",
    "    # Run 10 iterations of the MICE algorithm\n",
    "    mice_kernel.mice(10, n_jobs=10, max_depth = 3, n_estimators=50, oob_score=True, bootstrap=True)\n",
    "\n",
    "    # Return a training dataset filled\n",
    "    train_filled = mice_kernel.complete_data()\n",
    "    # Apply the trained imputer to a test dataset\n",
    "    test_filled = mice_kernel.impute_new_data(new_data=test_data)\n",
    "    # Return a test dataset filled\n",
    "    test_filled = test_filled.complete_data()\n",
    "    \n",
    "    return train_filled, test_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory imputing_7_no_ncvd failed (already exists?)\n",
      "Creation of the directory imputing_746_no_ncvd failed (already exists?)\n"
     ]
    }
   ],
   "source": [
    "# A directory to be created for the baseline (selected predictors) sample\n",
    "folder1 = \"imputing_7_{}\".format(folder_prefix)\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder1)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder1)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder1)\n",
    "\n",
    "    \n",
    "# A directory to be created for the high-dim sample\n",
    "folder2 = \"imputing_746_{}\".format(folder_prefix)\n",
    "\n",
    "try:\n",
    "    os.mkdir(folder2)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed (already exists?)\" % folder2)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(runs):\n",
    "    for cv in range(cv_splits):\n",
    "        train_data = pd.read_excel(\"splitting_7_{}/train_data_{}_{}.xlsx\".format(folder_prefix, r, cv), index_col = 0)\n",
    "        test_data = pd.read_excel(\"splitting_7_{}/test_data_{}_{}.xlsx\".format(folder_prefix, r, cv), index_col = 0)\n",
    "    \n",
    "        train_filled, test_filled = filling_gaps_small_data(train_data.loc[:, train_data.columns[:-1]], \n",
    "                                                            test_data.loc[:, test_data.columns[:-1]])\n",
    "        \n",
    "        train_filled['class'] = train_data['class'].copy()\n",
    "        test_filled['class'] = test_data['class'].copy()\n",
    "        \n",
    "        train_filled.to_excel(\"imputing_7_{}/train_filled_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "        test_filled.to_excel(\"imputing_7_{}/test_filled_{}_{}.xlsx\".format(folder_prefix, r, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. high-dimensional dataset\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the test part of high-dimensional data, there are often gaps in variables that do not have missing values in the training part. \n",
    "# Therefore, an imputer is trained on the joint dataset (train+test) again to fill gaps in the test part. \n",
    "# Gaps in the training part are filled without using the test part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Function:\n",
    "# Train an imputer with the MICE algorithm to fill gaps in training and test data\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def filling_gaps_big_data(train_data, test_data):\n",
    "    '''\n",
    "    Fill gaps in training and test data using MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: pd.DataFrame\n",
    "         predictors with gaps to train an imputer \n",
    "    test_data: pd.DataFrame\n",
    "         predictors with gaps to apply an imputer \n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    train_filled: pd.DataFrame\n",
    "        training data with filled gaps\n",
    "    test_filled: pd.DataFrame\n",
    "        test data with filled gaps\n",
    "    '''\n",
    "\n",
    "    # In this function, an imputer first is trained to fill gaps in the training data.\n",
    "    # Then, training samples without gaps are combined with test sampes with gaps\n",
    "    # and an inputer is trained again to fill gaps in the test data.\n",
    "    # This is done in this way because test examples have missing values in variables \n",
    "    # that have no gaps in the training data, therefore, the MICE imputer cannot fill\n",
    "    # them after training on the training data. \n",
    "    # This procedure immitates the real world scenario, when the model is first trained\n",
    "    # on some data, then other unseen data come for tests. \n",
    "    \n",
    "    # Create kernel \n",
    "    np.random.seed()\n",
    "\n",
    "    # Define parameters of the MICE algorithm from the miceforest package\n",
    "    mice_kernel = mf.KernelDataSet(\n",
    "    train_data,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=True,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "\n",
    "    # Run 10 iterations of the MICE algorithm\n",
    "    mice_kernel.mice(10, n_jobs=10, max_depth = 5, n_estimators=100, oob_score=True, bootstrap=True, verbose=False)\n",
    "\n",
    "    # Return a training dataset filled\n",
    "    train_filled = mice_kernel.complete_data()\n",
    "\n",
    "    # Train and test joint sample\n",
    "    test_starts = train_filled.shape[0]\n",
    "    all_samples = pd.concat([train_filled, test_data])\n",
    "    \n",
    "    print(\"Trained has been filled\")\n",
    "    \n",
    "    # Create kernel for all samples\n",
    "    np.random.seed()\n",
    "\n",
    "    mice_kernel_test = mf.KernelDataSet(\n",
    "    all_samples,\n",
    "    mean_match_candidates=5,\n",
    "    save_all_iterations=False,\n",
    "    save_models = 1,\n",
    "    random_state=None\n",
    "    )\n",
    "    \n",
    "    # Run the MICE algorithm for 10 iterations (to fill gaps in test samples)\n",
    "    mice_kernel_test.mice(10, n_jobs=10, max_depth = 5, n_estimators=100, oob_score=True, bootstrap=True, verbose=False)\n",
    "    \n",
    "    # Fill gaps in samples (gaps are in test samples)\n",
    "    all_samples_filled = mice_kernel_test.complete_data()\n",
    "\n",
    "    # Return filled test samples\n",
    "    test_filled = all_samples_filled.iloc[test_starts:,]\n",
    "    \n",
    "    print(\"Test has been filled\")\n",
    "    \n",
    "    return train_filled, test_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(runs):\n",
    "    print(\"Run: \", r)\n",
    "    for cv in range(cv_splits):\n",
    "        print(\"CV: \", cv)\n",
    "        train_data = pd.read_excel(\"splitting_746_{}/train_data_{}_{}.xlsx\".format(folder_prefix, r, cv), index_col = 0)\n",
    "        test_data = pd.read_excel(\"splitting_746_{}/test_data_{}_{}.xlsx\".format(folder_prefix, r, cv), index_col = 0)\n",
    "    \n",
    "        train_filled, test_filled = filling_gaps_big_data(train_data.loc[:, train_data.columns[:-1]], \n",
    "                                                            test_data.loc[:, test_data.columns[:-1]])\n",
    "        \n",
    "        train_filled['class'] = train_data['class'].copy()\n",
    "        test_filled['class'] = test_data['class'].copy()\n",
    "        \n",
    "        train_filled.to_excel(\"imputing_746_{}/train_filled_{}_{}.xlsx\".format(folder_prefix, r, cv))\n",
    "        test_filled.to_excel(\"imputing_746_{}/test_filled_{}_{}.xlsx\".format(folder_prefix, r, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate AUC in multiple runs\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline level\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Estimate AUC for the Logistic Regression model without regularization (FinRisk predictors), i.e. a baseline level\n",
    "# -----------------------------------------\n",
    "def auc_estimation_baseline(runs, cv_splits, folder):\n",
    "    auc_test_all = []\n",
    "    auc_train_all = []\n",
    "\n",
    "    for r in range(runs):\n",
    "        \n",
    "        for cv in range(cv_splits):\n",
    "            model = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=100000)\n",
    "            \n",
    "            data_train = pd.read_excel(folder + \"/train_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "            data_test = pd.read_excel(folder + \"/test_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "            \n",
    "            #data_train = data_train.loc[list(set(data_train.index) - set(index_ncvd))].copy()\n",
    "            #data_test = data_test.loc[list(set(data_test.index) - set(index_ncvd))].copy()\n",
    "            \n",
    "            data_x_train = data_train.loc[:, data_train.columns[:-1]].copy()\n",
    "            y_train = data_train.loc[:, 'class'].values\n",
    "            \n",
    "            data_x_test = data_test.loc[:, data_test.columns[:-1]].copy()\n",
    "            y_test = data_test.loc[:, 'class'].values\n",
    "            \n",
    "            #normalize\n",
    "            scaler = MinMaxScaler().fit(data_x_train)\n",
    "            data_x_train = scaler.transform(data_x_train)\n",
    "            data_x_test = scaler.transform(data_x_test)\n",
    "            #train the model\n",
    "            model.fit(data_x_train, y_train)\n",
    "            #apply to test\n",
    "            y_prob_test = [prediction[1] for prediction in model.predict_proba(data_x_test)]\n",
    "            auc_test_all.append(roc_auc_score(y_test, y_prob_test))\n",
    "            #apply to train\n",
    "            y_prob_train = [prediction[1] for prediction in model.predict_proba(data_x_train)]\n",
    "            auc_train_all.append(roc_auc_score(y_train, y_prob_train))\n",
    "\n",
    "    return np.array(auc_train_all), np.array(auc_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"imputing_7_{}\".format(folder_prefix)\n",
    "\n",
    "auc_train_baseline, auc_test_baseline = auc_estimation_baseline(runs, cv_splits, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Estimate a confidence interval\n",
    "# -----------------------------------------\n",
    "def CI_estimation(sample, confidence_level = 0.95):\n",
    "    degrees_freedom = sample.size - 1\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_standard_error = scipy.stats.sem(sample)\n",
    "    \n",
    "    confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
    "    print(sample_mean, '({0:.4f}, {1:.4f})'.format(confidence_interval[0], confidence_interval[1]))\n",
    "\n",
    "    return confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_estimation(auc_test_baseline, confidence_level = 0.95)\n",
    "CI_estimation(auc_train_baseline, confidence_level = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# Return predicted probabilities\n",
    "#--------------------------------\n",
    "def predict_baseline(runs, cv_splits, folder):\n",
    "    \n",
    "    y_prob_test = []    \n",
    "    y_true_test = []\n",
    "\n",
    "    for r in range(runs):    \n",
    "        for cv in range(cv_splits):\n",
    "            model = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=100000)\n",
    "\n",
    "            data_train = pd.read_excel(folder + \"/train_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "            data_test = pd.read_excel(folder + \"/test_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "\n",
    "            data_x_train = data_train.loc[:, data_train.columns[:-1]].copy()\n",
    "            y_train = data_train.loc[:, 'class'].values\n",
    "\n",
    "            data_x_test = data_test.loc[:, data_test.columns[:-1]].copy()\n",
    "            y_test = data_test.loc[:, 'class'].values\n",
    "\n",
    "            #normalize\n",
    "            scaler = MinMaxScaler().fit(data_x_train)\n",
    "            data_x_train = scaler.transform(data_x_train)\n",
    "            data_x_test = scaler.transform(data_x_test)\n",
    "\n",
    "            #train the model    \n",
    "            model.fit(data_x_train, y_train)\n",
    "\n",
    "            #apply to test\n",
    "            y_prob_test.extend([prediction[1] for prediction in model.predict_proba(data_x_test)])\n",
    "\n",
    "            y_true_test.extend(y_test)\n",
    "\n",
    "    return np.array(y_prob_test), np.array(y_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"imputing_7_{}\".format(folder_prefix)\n",
    "\n",
    "y_prob_test_baseline, y_true_test_baseline = predict_baseline(runs, cv_splits, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AUC for high-dimensional data\n",
    "___________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Perform cross-validation for the given data and model \n",
    "# -----------------------------------------\n",
    "def cv_estimator(cv_splits, data_x, data_y, model):\n",
    "    auc_test = []\n",
    "    auc_train = []\n",
    "    \n",
    "    splitting = StratifiedKFold(n_splits=cv_splits, random_state=None, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in splitting.split(np.zeros(data_y.shape[0]), data_y):\n",
    "        data_x_train, data_x_test = data_x.iloc[train_index].copy(), data_x.iloc[test_index].copy()\n",
    "        y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "        \n",
    "        #normalize\n",
    "        scaler = MinMaxScaler().fit(data_x_train)\n",
    "        data_x_train = scaler.transform(data_x_train)\n",
    "        data_x_test = scaler.transform(data_x_test)\n",
    "        #train the model\n",
    "        model.fit(data_x_train, y_train)\n",
    "        #apply to test\n",
    "        y_prob_test = [prediction[1] for prediction in model.predict_proba(data_x_test)]\n",
    "        auc_test.append(roc_auc_score(y_test, y_prob_test))\n",
    "        #apply to train\n",
    "        y_prob_train = [prediction[1] for prediction in model.predict_proba(data_x_train)]\n",
    "        auc_train.append(roc_auc_score(y_train, y_prob_train))\n",
    "        \n",
    "    return np.array(auc_train), np.array(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Estimate AUC on training, validation, and test data:\n",
    "# a model and its parameters are passed\n",
    "# a dataframe with results is returned\n",
    "# -----------------------------------------\n",
    "def auc_estimation(folder, runs, cv_splits, model, model_name, parameter):\n",
    "    \n",
    "    y_prob_test_all = []\n",
    "    y_test_all = []\n",
    "\n",
    "    auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "    predictions_all = pd.DataFrame(columns = ['true', 'predicted'])\n",
    "\n",
    "    for r in range(runs):\n",
    "        \n",
    "        for cv in range(cv_splits):\n",
    "\n",
    "            data_train = pd.read_excel(folder + \"/train_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "            data_test = pd.read_excel(folder + \"/test_filled_{}_{}.xlsx\".format(r, cv), index_col = 0)\n",
    "            \n",
    "            data_x_train = data_train.loc[:, data_train.columns[:-1]].copy()\n",
    "            y_train = data_train.loc[:, 'class'].values\n",
    "            \n",
    "            data_x_test = data_test.loc[:, data_test.columns[:-1]].copy()\n",
    "            y_test = data_test.loc[:, 'class'].values\n",
    "            \n",
    "            # -----------------------------------------\n",
    "            # Validation on the training data to choose the model parameters \n",
    "            # -----------------------------------------\n",
    "            auc_train_inside, auc_valid_inside = cv_estimator(cv_splits, data_x_train, y_train, model)\n",
    "            # -----------------------------------------\n",
    "            # -----------------------------------------\n",
    "            \n",
    "            #normalize\n",
    "            scaler = MinMaxScaler().fit(data_x_train)\n",
    "            data_x_train = scaler.transform(data_x_train)\n",
    "            data_x_test = scaler.transform(data_x_test)\n",
    "            #train the model\n",
    "            model.fit(data_x_train, y_train)\n",
    "            #apply to test\n",
    "            y_prob_test = [prediction[1] for prediction in model.predict_proba(data_x_test)]\n",
    "            auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "            #apply to train\n",
    "            y_prob_train = [prediction[1] for prediction in model.predict_proba(data_x_train)]\n",
    "            auc_train = roc_auc_score(y_train, y_prob_train)\n",
    "            \n",
    "            auc_summary = pd.concat( [auc_summary, pd.DataFrame({'run': r, 'cv': cv,\n",
    "            'auc_training': auc_train, 'auc_validation': str(list(auc_valid_inside)), 'auc_test': auc_test, \n",
    "            'model': model_name, 'parameter': parameter}, index=[0])], ignore_index=True)\n",
    "            \n",
    "            y_prob_test_all.extend(y_prob_test)\n",
    "            y_test_all.extend(y_test)\n",
    "\n",
    "    predictions_all['true'] = y_test_all\n",
    "    predictions_all['predicted'] = y_prob_test_all\n",
    "    \n",
    "    return auc_summary, predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_neighbors = [2, 4, 6, 8, 10, 12, 15, 20, 35]\n",
    "lambda_lasso = [0.025, 0.05, 0.075, 0.1, 0.15, 0.25, 0.5, 0.75, 1]\n",
    "tree_depth = [2, 3, 4, 5, 7, 9, 11, 13, 15]\n",
    "n_neurons = [3, 5, 10, 15, 30, 50, 100, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for KNeighborsClassifier\n",
    "# -----------------------------------------\n",
    "folder = \"imputing_746_{}\".format(folder_prefix)\n",
    "\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for knn in knn_neighbors:\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=knn, weights='uniform')\n",
    "    auc, predictions_test = auc_estimation(folder, runs, cv_splits, model_knn, 'k-Nearest Neighbors', knn)\n",
    "    auc_summary = pd.concat([auc_summary, auc], ignore_index=True)\n",
    "    predictions_test.to_excel('version_2_{}/predictions_test_KNeighborsClassifier_{}.xlsx'.format(folder_prefix, knn), index = False)\n",
    "\n",
    "auc_summary.to_excel('version_2_{}/auc_KNeighborsClassifier.xlsx'.format(folder_prefix), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for LogisticRegression\n",
    "# -----------------------------------------\n",
    "folder = \"imputing_746_{}\".format(folder_prefix)\n",
    "\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for lambd in lambda_lasso:\n",
    "    model_lasso = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=lambd)\n",
    "    auc, predictions_test = auc_estimation(folder, runs, cv_splits, model_lasso, 'Logistic Lasso Regression', lambd)\n",
    "    auc_summary = pd.concat([auc_summary, auc], ignore_index=True)\n",
    "    predictions_test.to_excel('version_2_{}/predictions_test_LogisticRegression_{}.xlsx'.format(folder_prefix, lambd), index = False)\n",
    "    \n",
    "auc_summary.to_excel('version_2_{}/auc_LogisticRegression.xlsx'.format(folder_prefix), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for DecisionTreeClassifier\n",
    "# -----------------------------------------\n",
    "folder = \"imputing_746_{}\".format(folder_prefix)\n",
    "\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for depth in tree_depth:\n",
    "    model_dt= DecisionTreeClassifier(max_depth=depth,class_weight=None) \n",
    "    auc, predictions_test = auc_estimation(folder, runs, cv_splits, model_dt, 'Decision Tree', depth)\n",
    "    auc_summary = pd.concat([auc_summary, auc], ignore_index=True)\n",
    "    predictions_test.to_excel('version_2_{}/predictions_test_DecisionTreeClassifier_{}.xlsx'.format(folder_prefix, depth), index = False)\n",
    "\n",
    "auc_summary.to_excel('version_2_{}/auc_DecisionTreeClassifier.xlsx'.format(folder_prefix), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for RandomForestClassifier\n",
    "# -----------------------------------------\n",
    "folder = \"imputing_746_{}\".format(folder_prefix)\n",
    "\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for depth in tree_depth:\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, max_depth=depth, bootstrap=True, oob_score=True)\n",
    "    auc, predictions_test = auc_estimation(folder, runs, cv_splits, model_rf, 'Random Forest', depth)\n",
    "    auc_summary = pd.concat([auc_summary, auc], ignore_index=True)\n",
    "    predictions_test.to_excel('version_2_{}/predictions_test_RandomForestClassifier_{}.xlsx'.format(folder_prefix, depth), index = False)\n",
    "\n",
    "auc_summary.to_excel('version_2_{}/auc_RandomForestClassifier.xlsx'.format(folder_prefix), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for MLPClassifier\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for neurons in n_neurons:\n",
    "    model_mlp = MLPClassifier(hidden_layer_sizes=(neurons, ), activation='relu', solver='adam', alpha=0.001, batch_size='auto',   ## hidden_layer_sizes=(round((inputsTrainingScaled.shape[1]+2)/2.), )\n",
    "                                                     learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=500, shuffle=True,\n",
    "                                                     random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "                                                     early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "\n",
    "    auc, predictions_test = auc_estimation(folder, runs, cv_splits, model_mlp, 'Multilayer Perceptron', neurons)\n",
    "    auc_summary = pd.concat([auc_summary, auc], ignore_index=True)\n",
    "    predictions_test.to_excel('version_2_{}/predictions_test_MLPClassifier_{}.xlsx'.format(folder_prefix, neurons), index = False)\n",
    "\n",
    "auc_summary.to_excel('version_2_{}/auc_MLPClassifier.xlsx'.format(folder_prefix), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing the results\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Import the results for all the models\n",
    "# -----------------------------------------\n",
    "\n",
    "knn_neighbors = [2, 4, 6, 8, 10, 12, 15, 20, 35]\n",
    "lambda_lasso = [0.025, 0.05, 0.075, 0.1, 0.15, 0.25, 0.5, 0.75, 1]\n",
    "tree_depth = [2, 3, 4, 5, 7, 9, 11, 13, 15]\n",
    "n_neurons = [3, 5, 10, 15, 30, 50, 100, 300, 400]\n",
    "\n",
    "\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "\n",
    "auc_knn = pd.read_excel('version_2_{}/auc_KNeighborsClassifier.xlsx'.format(folder_prefix))\n",
    "auc_summary = pd.concat([auc_summary, auc_knn], ignore_index=True)\n",
    "\n",
    "auc_lasso = pd.read_excel('version_2_{}/auc_LogisticRegression.xlsx'.format(folder_prefix))\n",
    "auc_summary = pd.concat([auc_summary, auc_lasso], ignore_index=True)\n",
    "\n",
    "auc_dt = pd.read_excel('version_2_{}/auc_DecisionTreeClassifier.xlsx'.format(folder_prefix))\n",
    "auc_summary = pd.concat([auc_summary, auc_dt], ignore_index=True)\n",
    "\n",
    "auc_rf = pd.read_excel('version_2_{}/auc_RandomForestClassifier2.xlsx'.format(folder_prefix))\n",
    "auc_summary = pd.concat([auc_summary, auc_rf], ignore_index=True)\n",
    "\n",
    "auc_mlp = pd.read_excel('version_2_{}/auc_MLPClassifier.xlsx'.format(folder_prefix))\n",
    "auc_summary = pd.concat([auc_summary, auc_mlp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Modify the results' format for drawing figures and tables\n",
    "# -----------------------------------------\n",
    "def prepare_for_boxplots(auc):\n",
    "    \n",
    "    # Boxplots\n",
    "    auc.columns = ['run', 'cv', 'training', 'validation', 'test', 'model', 'parameter']\n",
    "\n",
    "    df1 = pd.melt(auc, id_vars=['run', 'cv', 'model', 'parameter'], value_vars=['training', 'test'])\n",
    "    df1.columns = ['run', 'cv', 'model', 'parameter', 'sample', 'AUC']\n",
    "\n",
    "    for i in range(auc.shape[0]):\n",
    "        auc_valid = [float(item) for item in auc.loc[i, 'validation'][1:-1].split(', ')]\n",
    "    \n",
    "        for item in auc_valid:\n",
    "            df1 = df1.append({'run': auc.loc[i, 'run'], 'cv': auc.loc[i, 'cv'], 'model': auc.loc[i, 'model'],\n",
    "                        'parameter': auc.loc[i, 'parameter'], 'sample': 'validation', 'AUC': item},\n",
    "                         ignore_index = True)\n",
    "    \n",
    "    # Confidence intervals\n",
    "    df2 = pd.DataFrame(columns = ['mean', 'ci', 'sample', 'parameter', 'model'])\n",
    "    for prmtr in df1['parameter'].unique():\n",
    "        for smpl in ['training', 'validation', 'test']:\n",
    "            selected = (df1.loc[:, 'parameter'] == prmtr) & (df1.loc[:, 'sample'] == smpl)\n",
    "            df2 = df2.append({'mean': df1.loc[selected, 'AUC'].mean(), \n",
    "                              'ci': CI_estimation(df1.loc[selected, 'AUC'])[1] - df1.loc[selected, 'AUC'].mean(), \n",
    "                              'sample': smpl, 'parameter': prmtr, 'model': auc.loc[0, 'model']},\n",
    "                               ignore_index = True)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Apply modifications to the results\n",
    "# -----------------------------------------\n",
    "data_for_boxplots = pd.DataFrame()\n",
    "auc_stats = pd.DataFrame()\n",
    "\n",
    "auc_knn_melted, auc_knn_stats = prepare_for_boxplots(auc_knn)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_knn_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_knn_stats], ignore_index = True)\n",
    "\n",
    "auc_lasso_melted, auc_lasso_stats = prepare_for_boxplots(auc_lasso)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_lasso_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_lasso_stats], ignore_index = True)\n",
    "\n",
    "auc_dt_melted, auc_dt_stats = prepare_for_boxplots(auc_dt)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_dt_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_dt_stats], ignore_index = True)\n",
    "\n",
    "auc_rf_melted, auc_rf_stats = prepare_for_boxplots(auc_rf)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_rf_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_rf_stats], ignore_index = True)\n",
    "\n",
    "auc_mlp_melted, auc_mlp_stats = prepare_for_boxplots(auc_mlp)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_mlp_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_mlp_stats], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Produce boxplots for AUCs\n",
    "# -----------------------------------------\n",
    "def draw_boxplots(data_for_boxplots):\n",
    "\n",
    "    data_for_boxplots.columns = ['run', 'cv', 'model', 'parameter', 'Sample: ', 'AUC']\n",
    "    fig = px.box(data_for_boxplots, x='parameter', y='AUC', facet_row='model', color='Sample: ', \n",
    "                 color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "    category_orders={'Sample: ': ['training', 'validation', 'test']})\n",
    "    \n",
    "    fig.update_yaxes(matches=None) \n",
    "    fig.update_xaxes(matches=None, type='category', showticklabels=True, title = '')\n",
    "\n",
    "    fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "    fig.update_traces(legendgroup = 'main')\n",
    "    \n",
    "    fig.update_layout(\n",
    "    font_size = 25,\n",
    "    autosize=True,\n",
    "    width=1700,\n",
    "    height=2500)\n",
    "\n",
    "    \n",
    "    \n",
    "    fig.add_scatter(x=[2, 35], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=5, col=1) \n",
    "    fig.add_scatter(x=[0.025, 1], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=4, col=1) \n",
    "    fig.add_scatter(x=[2, 15], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=3, col=1) \n",
    "    fig.add_scatter(x=[2, 15], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=2, col=1) \n",
    "    fig.add_scatter(x=[3, 400], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, \n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=1, col=1) \n",
    "        \n",
    "    fig.update_layout(legend=dict( tracegroupgap = 50,\n",
    "    orientation='h', traceorder = 'grouped',\n",
    "    #yanchor='bottom', \n",
    "    bordercolor = 'gray',\n",
    "    y=0.055,\n",
    "    #xanchor='center',\n",
    "    x=0.615))\n",
    "    \n",
    "    fig.add_annotation(row=5,col=1, x=4, y=0.45, showarrow=False, text='The number of nearest neighbors')\n",
    "    fig.add_annotation(row=4,col=1, x=4, y=0.55, showarrow=False, text='Regularization')\n",
    "    fig.add_annotation(row=3,col=1, x=4, y=0.35, showarrow=False, text='Decision tree depth')\n",
    "    fig.add_annotation(row=2,col=1, x=4, y=0.55, showarrow=False, text='Decision tree depth')\n",
    "    fig.add_annotation(row=1,col=1, x=4, y=0.325, showarrow=False, text='The number of neurons')\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    plotly.offline.plot(fig, filename = 'version_2_{}/AUCs.html'.format(folder_prefix), auto_open=True)\n",
    "    \n",
    "    \n",
    "draw_boxplots(data_for_boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# -----------------------------------------\n",
    "# Produce tables with 95%CIs for AUCs\n",
    "# -----------------------------------------\n",
    "def get_info_for_CI_table(auc_stats, model):\n",
    "    \n",
    "    selected = (auc_stats.loc[:, 'model'] == model)\n",
    "    col1 = auc_stats.loc[selected, 'parameter'].unique()\n",
    "    \n",
    "    col2 = []\n",
    "    col3 = []\n",
    "    col4 = []\n",
    "    \n",
    "    for prmtr in col1:  \n",
    "        selected_prmtr = selected & (auc_stats.loc[:, 'parameter'] == prmtr)\n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'training'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'training'), 'ci'].values[0]\n",
    "        col2.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "        \n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'validation'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'validation'), 'ci'].values[0]\n",
    "        col3.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "        \n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'test'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'test'), 'ci'].values[0]\n",
    "        col4.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "    \n",
    "    return col1, col2, col3, col4\n",
    "\n",
    "\n",
    "def create_CI_tables(auc_stats):\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=5, cols=1, vertical_spacing=0.05,\n",
    "        specs=[[{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}]],\n",
    "        subplot_titles=[\n",
    "            'k-Nearest Neighbors', \n",
    "            'Logistic Lasso Regression',\n",
    "            'Decision Tree',\n",
    "            'Random Forest',\n",
    "            'Multilayer Perceptron'])\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'k-Nearest Neighbors')\n",
    "    fig.add_trace(go.Table(header=dict(values=['The number of nearest neighbors', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 1, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Logistic Lasso Regression')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Regularization', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 2, col = 1)\n",
    "    \n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Decision Tree')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Decision tree depth', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 3, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Random Forest')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Decision tree depth', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 4, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Multilayer Perceptron')\n",
    "    fig.add_trace(go.Table(header=dict(values=['The number of neurons', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 5, col = 1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "    autosize=True,\n",
    "    #width=2000,\n",
    "    height=1600)\n",
    "    fig.show()\n",
    "\n",
    "    plotly.offline.plot(fig, filename = 'CI AUCs eq hor.html', auto_open=False)\n",
    "\n",
    "    \n",
    "create_CI_tables(auc_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Save CI-tables in excel\n",
    "# --------------------------\n",
    "def create_CI_tables_excel(auc_stats, model_name, parameter):\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, model_name)\n",
    "    \n",
    "    df = pd.DataFrame({parameter: col1, \n",
    "                       'Training data: AUC mean (95%CI)': col2, \n",
    "                       'Validation data: AUC mean (95%CI)': col3, \n",
    "                       'Test data: AUC mean (95%CI)': col4})\n",
    "    \n",
    "    \n",
    "    df.to_excel(\"version_2_ncvd/{}_95CI.xlsx\".format(model_name))\n",
    "\n",
    "\n",
    "model_names=['k-Nearest Neighbors', \n",
    "            'Logistic Lasso Regression',\n",
    "            'Decision Tree',\n",
    "            'Random Forest',\n",
    "            'Multilayer Perceptron']\n",
    "\n",
    "parameters = ['The number of nearest neighbors', \n",
    "              'Regularization', \n",
    "              'Decision tree depth', \n",
    "              'Decision tree depth', \n",
    "              'The number of neurons']\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    create_CI_tables_excel(auc_stats, model_name, parameters[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Draw calibration curves\n",
    "# -------------------------\n",
    "\n",
    "plt.subplots(figsize = (10,5))\n",
    "\n",
    "# Baseline curve\n",
    "prob_true_baseline, prob_pred_baseline = calibration_curve(y_true_test_baseline, y_prob_test_baseline, n_bins=10, normalize = False)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color = 'black')\n",
    "plt.plot(prob_pred_baseline, prob_true_baseline, marker = 'o', color = 'orange', label = 'Baseline')\n",
    "\n",
    "# Calibration curves for the selected models\n",
    "models = ['k-Nearest Neighbors', 'Logistic Lasso Regression', 'Decision Tree',\n",
    "            'Random Forest', 'Multilayer Perceptron']\n",
    "\n",
    "model_file = {'k-Nearest Neighbors': 'KNeighborsClassifier', 'Logistic Lasso Regression': 'LogisticRegression',\n",
    "             'Decision Tree': 'DecisionTreeClassifier', 'Random Forest': 'RandomForestClassifier2',\n",
    "             'Multilayer Perceptron': 'MLPClassifier'}\n",
    "\n",
    "model_color = {'k-Nearest Neighbors': 'red', 'Logistic Lasso Regression': 'blue', 'Decision Tree': 'green',\n",
    "            'Random Forest': 'purple', 'Multilayer Perceptron': 'brown'}\n",
    "\n",
    "\n",
    "if scenario == 0:\n",
    "    parameters = {'k-Nearest Neighbors': [35], 'Logistic Lasso Regression': [0.25], 'Decision Tree': [3],\n",
    "                'Random Forest': [5], 'Multilayer Perceptron': [100]}\n",
    "else:\n",
    "    parameters = {'k-Nearest Neighbors': [35], 'Logistic Lasso Regression': [0.15, 0.25], 'Decision Tree': [3],\n",
    "                'Random Forest': [3,4,5,7], 'Multilayer Perceptron': [400]}\n",
    "    \n",
    "\n",
    "line_types = ['solid', 'dotted', 'dashed', 'dashdot']\n",
    "\n",
    "for model in models:\n",
    "    params = parameters[model]\n",
    "    for i, param in enumerate(params):\n",
    "        predictions = pd.read_excel('version_2_{}/predictions_test_{}_{}.xlsx'.format(folder_prefix, model_file[model], param))\n",
    "        prob_true, prob_pred = calibration_curve(predictions.loc[:, 'true'].values, predictions.loc[:, 'predicted'].values, \n",
    "                                             n_bins=10, normalize = False)\n",
    "\n",
    "        if i < 3:\n",
    "            plt.plot(prob_pred, prob_true, marker = 'o', linestyle=line_types[i], color = model_color[model], \n",
    "                     label = '{}({})'.format(model, param))\n",
    "        else:\n",
    "            plt.plot(prob_pred, prob_true, linestyle=line_types[i], color = model_color[model], \n",
    "                     label = '{}({})'.format(model, param))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Predicted risk')\n",
    "plt.ylabel('Observed risk')\n",
    "\n",
    "plt.savefig('calibration plot {}.png'.format(folder_prefix), dpi = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "knn_neighbors = [2, 4, 6, 8, 10, 12, 15, 20, 35]\n",
    "lambda_lasso = [0.025, 0.05, 0.075, 0.1, 0.15, 0.25, 0.5, 0.75, 1]\n",
    "tree_depth = [2, 3, 4, 5, 7, 9, 11, 13, 15]\n",
    "n_neurons = [3, 5, 10, 15, 30, 50, 100, 300, 400]\n",
    "\n",
    "# Select samples to compare:\n",
    "dataset = 'validation' # or dataset = 'test'\n",
    "\n",
    "if scenario == 0:\n",
    "    dataset = 'validation'\n",
    "    param1 = lambda_lasso[4]\n",
    "    param2 = lambda_lasso[5]\n",
    "    \n",
    "    sample1 = auc_lasso_melted.loc[ (auc_lasso_melted.loc[:, 'sample'] == dataset) & (auc_lasso_melted.loc[:, 'parameter'] == param1), 'AUC'].values\n",
    "    sample2 = auc_lasso_melted.loc[ (auc_lasso_melted.loc[:, 'sample'] == dataset) & (auc_lasso_melted.loc[:, 'parameter'] == param2), 'AUC'].values\n",
    "\n",
    "    print(param1, param2)\n",
    "    f_oneway(sample1, sample2)\n",
    "    \n",
    "else:\n",
    "    param1 = lambda_lasso[4]\n",
    "    param2 = lambda_lasso[5]\n",
    "    \n",
    "    param3 = tree_depth[1]\n",
    "    param4 = tree_depth[2]\n",
    "    param5 = tree_depth[3]\n",
    "    param6 = tree_depth[4]\n",
    "    \n",
    "    sample1 = auc_lasso_melted.loc[ (auc_lasso_melted.loc[:, 'sample'] == dataset) & (auc_lasso_melted.loc[:, 'parameter'] == param1), 'AUC'].values\n",
    "    sample2 = auc_lasso_melted.loc[ (auc_lasso_melted.loc[:, 'sample'] == dataset) & (auc_lasso_melted.loc[:, 'parameter'] == param2), 'AUC'].values\n",
    "\n",
    "    sample3 = auc_rf_melted.loc[ (auc_rf_melted.loc[:, 'sample'] == dataset) & (auc_rf_melted.loc[:, 'parameter'] == param3), 'AUC'].values\n",
    "    sample4 = auc_rf_melted.loc[ (auc_rf_melted.loc[:, 'sample'] == dataset) & (auc_rf_melted.loc[:, 'parameter'] == param4), 'AUC'].values\n",
    "    sample5 = auc_rf_melted.loc[ (auc_rf_melted.loc[:, 'sample'] == dataset) & (auc_rf_melted.loc[:, 'parameter'] == param5), 'AUC'].values\n",
    "    sample6 = auc_rf_melted.loc[ (auc_rf_melted.loc[:, 'sample'] == dataset) & (auc_rf_melted.loc[:, 'parameter'] == param6), 'AUC'].values\n",
    "\n",
    "    print(param1, param2, param3, param4, param5, param6)\n",
    "\n",
    "    f_oneway(sample1, sample2, sample3, sample4, sample5, sample6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional analysis\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values examination\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 994)\n",
      "KIHD with genes only: (2682, 96)\n",
      "KIHD with phenotypes only: (2682, 977)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Keep the original data in 'data_kihd' and use its copy 'data_kihd_preprocessed' instead\n",
    "# -----------------------------------------\n",
    "data_kihd_preprocessed = data_kihd.copy()\n",
    "\n",
    "# Drop two variables (dates of visits)\n",
    "#data_kihd_preprocessed = data_kihd_preprocessed.drop(['tpvm2', 'tpnr2'], axis = 1)\n",
    "\n",
    "# Correct the zero-level for the following variables:\n",
    "wrong_zero = ['v0563', 'v0565', 'v0567', 'v0569', 'v0571', 'v0573', 'v0575', 'v0577', 'v0579', 'v0607', 'v0609', 'v0613',\n",
    "              'v0621', 'v0623', 'v0625', 'v0627', 'v0629', 'v0631', 'v0633', 'v0635', 'v0637', 'v0639', 'v0643', 'v0645', \n",
    "              'v0647', 'v0649', 'v0651', 'v0653']\n",
    "# Zeros are at the wrong end of the scale\n",
    "# Change zeros to (max+1)\n",
    "for col in wrong_zero:\n",
    "    data_kihd_preprocessed.loc[:, col] = [np.max(data_kihd_preprocessed.loc[:, col]) + 1 if value == 0.0 else value for value in data_kihd_preprocessed.loc[:, col]]\n",
    "\n",
    "print(data_kihd_preprocessed.shape)\n",
    "# -----------------------------------------\n",
    "# Turn the categorical variables indo dummies\n",
    "# -----------------------------------------\n",
    "categorical_variables=['au0136','au0153','ek0115','ek0119','ka0118','mi0205','mi0207','mi0208','mi0209',\n",
    "                       'mi0210','mi0211','mi0212','mi0213','mi0214','v0145','v0146','v0157','v0158','v0161',\n",
    "                       'v0172','v0247','v0248','v0665','v0721','v0724','u1307']\n",
    "\n",
    "for col in categorical_variables:\n",
    "    if col in data_kihd_preprocessed.columns:\n",
    "        new_dummies=pd.get_dummies(data_kihd_preprocessed[col], dummy_na=False)\n",
    "        my_list = new_dummies.columns.values\n",
    "        string = col+\"_\"\n",
    "        my_new_list = [string + str(x) for x in my_list]\n",
    "        new_dummies.columns = my_new_list\n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.drop(col, axis=1)       \n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.join(new_dummies)\n",
    "                 \n",
    "# Outcomes\n",
    "kihd_outcomes = data_kihd_preprocessed.loc[:, ['tutknro', 'tpvm2', 'tpnr2', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d']]\n",
    "\n",
    "# Predictors\n",
    "kihd_predictors = data_kihd_preprocessed.drop(['tutknro', 'tpvm2', 'tpnr2', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d'], axis = 1)\n",
    "\n",
    "# Separate genes and phenotypes\n",
    "genes_start = list(kihd_predictors.columns.values).index('FEDER2HH'.lower())\n",
    "genes_end = list(kihd_predictors.columns.values).index('CATAETT'.lower())\n",
    "\n",
    "# Genes only\n",
    "kihd_genes = kihd_predictors.iloc[:, genes_start:(genes_end+1)].copy()\n",
    "print(\"KIHD with genes only: {}\".format(kihd_genes.shape))\n",
    "\n",
    "# Phenotypes\n",
    "kihd_phenotypes = kihd_predictors.drop(kihd_predictors.columns.values[genes_start:genes_end+1], axis = 1)\n",
    "print(\"KIHD with phenotypes only: {}\".format(kihd_phenotypes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for the examination\n",
    "kihd_7_inputs_na = kihd_phenotypes.loc[:, ['v0137', 'tup', 'mvp0224', 'bi0160', 'bi0171', 'diab', 'cvdfam']].copy()\n",
    "kihd_7_inputs_na.columns = ['age', 'smoking', 'sbp', 'tc', 'hdl', 'diabetes', 'fam_hist']\n",
    "\n",
    "kihd_7_inputs_na.to_excel(\"kihd_7_inputs_na.xlsx\", index = False)\n",
    "kihd_7_inputs_na = kihd_7_inputs_na.isna()\n",
    "\n",
    "kihd_7_inputs_na['cvd'] = kihd_outcomes.loc[:, 'cvd16'].copy()\n",
    "kihd_7_inputs_na['ncvd'] = kihd_outcomes.loc[:, 'ncvd16'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess pattern data\n",
    "missing_pattern = np.unique(np.array(kihd_7_inputs_na.values.astype('int')), axis = 0, return_counts = True)\n",
    "missing_pattern_df = pd.DataFrame(missing_pattern[0], columns = ['age', 'smoking', 'sbp', 'tc', 'hdl', 'diabetes', 'fam_hist', 'cvd', 'ncvd'])\n",
    "missing_pattern_df['counts'] = missing_pattern[1]/kihd_7_inputs_na.shape[0] * 100\n",
    "missing_pattern_df['counts'] = missing_pattern_df['counts'].apply(lambda x: round(x, 2))\n",
    "missing_pattern_df = missing_pattern_df.sort_values(['cvd', 'ncvd', 'age', 'smoking', 'tc', 'hdl', 'diabetes', 'fam_hist', 'hdl', 'tc', 'sbp'])\n",
    "\n",
    "missing_pattern_df = missing_pattern_df.reset_index(drop=True)\n",
    "missing_pattern_df.index = [0,1,3,2,4,5,7,6,8,9,10,11]\n",
    "missing_pattern_df = missing_pattern_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize patterns\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize = (30,10))\n",
    "\n",
    "# cvd\n",
    "#plt.subplot(1,1)\n",
    "f1 = sn.heatmap(missing_pattern_df.loc[missing_pattern_df.loc[:, 'cvd'] == 1, missing_pattern_df.columns[:-3]], linewidths=.25, cmap=\"Accent\", \n",
    "           xticklabels=['age', 'smoking', 'sbp', 'tc', 'hdl', 'diabetes', 'fam_hist'],\n",
    "           yticklabels= missing_pattern_df.loc[missing_pattern_df.loc[:, 'cvd'] == 1, 'counts'],\n",
    "           square=True, cbar=False, \n",
    "           ax=ax[0])\n",
    "f1.set_xticklabels(f1.get_xmajorticklabels(), fontsize = 20, rotation=45)\n",
    "f1.set_yticklabels(f1.get_ymajorticklabels(), fontsize = 20, rotation=0)\n",
    "f1.set_title(\"Cardiovascular death by the end of 2016\", fontsize = 20)\n",
    "f1.set_ylabel(\"Percentage in the cohort, %\", fontsize = 20)\n",
    "\n",
    "# healthy\n",
    "#plt.subplot(1,2)\n",
    "f2 = sn.heatmap(missing_pattern_df.loc[(missing_pattern_df.loc[:, 'cvd'] == 0) & (missing_pattern_df.loc[:, 'ncvd'] == 0), missing_pattern_df.columns[:-3]], \n",
    "           linewidths=.25, cmap=\"Accent\", \n",
    "           xticklabels = ['age', 'smoking', 'sbp', 'tc', 'hdl', 'diabetes', 'fam_hist'],\n",
    "           yticklabels = missing_pattern_df.loc[(missing_pattern_df.loc[:, 'cvd'] == 0) & (missing_pattern_df.loc[:, 'ncvd'] == 0), 'counts'],\n",
    "           square=True, cbar=False,\n",
    "           ax=ax[1])\n",
    "f2.set_xticklabels(f2.get_xmajorticklabels(), fontsize = 20, rotation=45)\n",
    "f2.set_yticklabels(f2.get_ymajorticklabels(), fontsize = 20, rotation=0)\n",
    "#f2.set_title(\"Alive by the end of 2016\", fontsize = 20)\n",
    "f2.set_title(\"Missing values\", fontsize = 20)\n",
    "\n",
    "# ncvd\n",
    "#plt.subplot(1,3)\n",
    "f3 = sn.heatmap(missing_pattern_df.loc[missing_pattern_df.loc[:, 'ncvd'] == 1, missing_pattern_df.columns[:-3]], linewidths=.25, cmap=\"Accent\", \n",
    "           xticklabels=['age', 'smoking', 'sbp', 'tc', 'hdl', 'diabetes', 'fam_hist'],\n",
    "           yticklabels = missing_pattern_df.loc[missing_pattern_df.loc[:, 'ncvd'] == 1, 'counts'],\n",
    "           square=True, cbar=False,\n",
    "           ax = ax[2])\n",
    "f3.set_xticklabels(f3.get_xmajorticklabels(), fontsize = 20, rotation=45)\n",
    "f3.set_yticklabels(f3.get_ymajorticklabels(), fontsize = 20, rotation=0)\n",
    "#f3.set_title(\"Non-cardiovarcular death by the end of 2016\", fontsize = 20)\n",
    "f3.set_title(\"Non-missing values\", fontsize = 20)\n",
    "\n",
    "#plt.savefig(\"miss_patterns2.png\", dpi = 400, transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "# Load the rpy2 IPython extension into the notebook to use R with a magic command: %%R\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# :::::::::\n",
    "# R kernel\n",
    "# :::::::::\n",
    "\n",
    "install.packages(\"finalfit\")\n",
    "install.packages(\"readxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 600 -h 650\n",
    "# :::::::::\n",
    "# R kernel\n",
    "# :::::::::\n",
    "\n",
    "# Missing data patterns\n",
    "\n",
    "library(\"finalfit\")\n",
    "library(\"readxl\")\n",
    "\n",
    "# Import key variables\n",
    "kihd_7_inputs_na <- read_excel(\"kihd_7_inputs_na.xlsx\")\n",
    "\n",
    "# Change types of categorical variables\n",
    "kihd_7_inputs_na$smoking <- as.factor(kihd_7_inputs_na$smoking)\n",
    "kihd_7_inputs_na$diabetes <- as.factor(kihd_7_inputs_na$diabetes)\n",
    "kihd_7_inputs_na$fam_hist <- as.factor(kihd_7_inputs_na$fam_hist)\n",
    "\n",
    "# Create a plot of variable distributions conditional on presence and missingness of other variables \n",
    "missing_pairs(kihd_7_inputs_na, position = \"fill\", showYAxisPlotLabels = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important variables\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"imputing_746_{}\".format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(folder_name + \"/train_filled_0_0.xlsx\", index_col = 0)\n",
    "test_data = pd.read_excel(folder_name + \"/test_filled_0_0.xlsx\", index_col = 0)\n",
    "\n",
    "data = pd.concat([train_data, test_data], ignore_index = True)\n",
    "data_x = data.loc[:, data.columns[:-1]]\n",
    "data_y = data.loc[:, 'class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "import collections\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "\n",
    "data_x = data_x.rename(columns={\"v0137\": \"AGE\",\n",
    "                      \"li02met\": \"ACTIVITY\",\n",
    "                      \"packyear\": \"PACKYEAR\",\n",
    "                      \"cigyears\": \"CIGYEAR\",\n",
    "                      \"v1151\": \"NITROMED\",\n",
    "                      \"v0750\": \"SMOKING\",\n",
    "                      \"crpk\": \"CRP\",\n",
    "                      \"bi0222\": \"VITAMINC\",\n",
    "                      \"homa1ir\": \"HOMAIR1\",\n",
    "                      \"v0868\": \"AMIDG\",\n",
    "                      \"mvp0134\": \"SYSTOLICB\",\n",
    "                      \"v0860\": \"HEALTHSTATE\",\n",
    "                      \"apob\": \"APOB\",\n",
    "                      \"nicmgd\": \"NICOTIN\",\n",
    "                      \"exihd\": \"ISCHAEMIA\"})\n",
    "\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth=3,random_state=None) \n",
    "dt.fit(data_x, data_y)\n",
    "    \n",
    "dot_data = tree.export_graphviz(dt,\n",
    "                    feature_names=data_x.columns.values,\n",
    "                    out_file=None,\n",
    "                    class_names = [\"no cv death\", \"cv death\"], \n",
    "                    filled=True,\n",
    "                    rounded=True)\n",
    "    \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "colors = ('orange', 'lightblue')\n",
    "colors = {'no cv death': 'lightblue', 'cv death': 'orange'}\n",
    "edges = collections.defaultdict(list)\n",
    "\n",
    "for edge in graph.get_edge_list():\n",
    "    edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "for node in graph.get_nodes():\n",
    "    print(node.get_label())\n",
    "    if node.get_label() != None:\n",
    "        if node.get_label().endswith('no cv death\"'):\n",
    "            node.set_fillcolor(colors['no cv death'])\n",
    "        else:\n",
    "            node.set_fillcolor(colors['cv death'])\n",
    "\n",
    "graph.write_png('{}_tree3.png'.format(folder_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "scaler = MinMaxScaler().fit(data_x)\n",
    "data_x_scaled = scaler.transform(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Lasso\n",
    "runs = 50\n",
    "\n",
    "weights = np.zeros(data_x_scaled.shape[1])\n",
    "\n",
    "for r in range(runs):\n",
    "    \n",
    "    lambd = 0.25\n",
    "    model_lasso = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=lambd)\n",
    "\n",
    "    model_lasso.fit(data_x_scaled, data_y)\n",
    "    weights=weights + model_lasso.coef_[0]/runs\n",
    "\n",
    "    \n",
    "result_importance=pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "\n",
    "for j in range(len(data_x.columns.values)):\n",
    "      result_importance=result_importance.append({'Feature': data_x.columns.values[j], 'Importance': weights[j]}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_importance[\"abs imp\"] = result_importance.loc[:, 'Importance'].apply(abs)\n",
    "result_importance = result_importance.sort_values(['abs imp'], ascending=False)\n",
    "result_importance.to_excel(\"{}_lasso_vars_importance.xlsx\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "runs = 50\n",
    "\n",
    "weights = np.zeros(data_x_scaled.shape[1])\n",
    "\n",
    "for r in range(runs):\n",
    "    \n",
    "    tree_depth = 5\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, max_depth=tree_depth, bootstrap=True, oob_score=True)\n",
    "    model_rf.fit(data_x_scaled, data_y)\n",
    "    \n",
    "    weights=weights + model_rf.feature_importances_/runs\n",
    "    \n",
    "result_importance=pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "\n",
    "for j in range(len(data_x.columns.values)):\n",
    "      result_importance=result_importance.append({'Feature': data_x.columns.values[j], 'Importance': weights[j]}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_importance = result_importance.sort_values(['Importance'], ascending=False)\n",
    "result_importance.to_excel(\"{}_forest_vars_importance.xlsx\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
