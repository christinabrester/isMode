{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fancyimpute import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all samples from the file\n",
    "data_kihd = pd.read_excel('kihd_may_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 992)\n",
      "KIHD with genes only: (2682, 96)\n",
      "KIHD with phenotypes only: (2682, 977)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Keep the original data in 'data_kihd' and use its copy 'data_kihd_preprocessed' instead\n",
    "# -----------------------------------------\n",
    "data_kihd_preprocessed = data_kihd.copy()\n",
    "\n",
    "# Drop two variables (dates of visits)\n",
    "data_kihd_preprocessed = data_kihd_preprocessed.drop(['tpvm2', 'tpnr2'], axis = 1)\n",
    "\n",
    "# Correct the zero-level for the following variables:\n",
    "wrong_zero = ['v0563', 'v0565', 'v0567', 'v0569', 'v0571', 'v0573', 'v0575', 'v0577', 'v0579', 'v0607', 'v0609', 'v0613',\n",
    "              'v0621', 'v0623', 'v0625', 'v0627', 'v0629', 'v0631', 'v0633', 'v0635', 'v0637', 'v0639', 'v0643', 'v0645', \n",
    "              'v0647', 'v0649', 'v0651', 'v0653']\n",
    "# Zeros are at the wrong end of the scale\n",
    "# Change zeros to (max+1)\n",
    "for col in wrong_zero:\n",
    "    data_kihd_preprocessed.loc[:, col] = [np.max(data_kihd_preprocessed.loc[:, col]) + 1 if value == 0.0 else value for value in data_kihd_preprocessed.loc[:, col]]\n",
    "\n",
    "print(data_kihd_preprocessed.shape)\n",
    "# -----------------------------------------\n",
    "# Turn the categorical variables indo dummies\n",
    "# -----------------------------------------\n",
    "categorical_variables=['au0136','au0153','ek0115','ek0119','ka0118','mi0205','mi0207','mi0208','mi0209',\n",
    "                       'mi0210','mi0211','mi0212','mi0213','mi0214','v0145','v0146','v0157','v0158','v0161',\n",
    "                       'v0172','v0247','v0248','v0665','v0721','v0724','u1307']\n",
    "\n",
    "for col in categorical_variables:\n",
    "    if col in data_kihd_preprocessed.columns:\n",
    "        new_dummies=pd.get_dummies(data_kihd_preprocessed[col], dummy_na=False)\n",
    "        my_list = new_dummies.columns.values\n",
    "        string = col+\"_\"\n",
    "        my_new_list = [string + str(x) for x in my_list]\n",
    "        new_dummies.columns = my_new_list\n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.drop(col, axis=1)       \n",
    "        data_kihd_preprocessed = data_kihd_preprocessed.join(new_dummies)\n",
    "                 \n",
    "# Outcomes\n",
    "kihd_outcomes = data_kihd_preprocessed.loc[:, ['tutknro', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d']]\n",
    "\n",
    "# Predictors\n",
    "kihd_predictors = data_kihd_preprocessed.drop(['tutknro', 'chdb16', 'chdb16d', 'amif16', 'amif16d', 'amig16', 'amig16d',\n",
    "       'amim16', 'amim16d', 'all16', 'all16d', 'cvd16', 'cvd16d', 'syd14', 'alzm14', 'vp14', 'kol14', 'diab14',\n",
    "       'ncvd16', 'ncvd16d', 'cv15', 'cv15d', 'all15', 'stro15', 'cvd15', 'chd15', 'amib15', 'isth15', 'hsth15', \n",
    "                                'db15', 'can15', 'canc15', 'ast15', 'copd15', 'dema15', 'finchd18', 'finchd18d'], axis = 1)\n",
    "\n",
    "# Separate genes and phenotypes\n",
    "genes_start = list(kihd_predictors.columns.values).index('FEDER2HH'.lower())\n",
    "genes_end = list(kihd_predictors.columns.values).index('CATAETT'.lower())\n",
    "\n",
    "# Genes only\n",
    "kihd_genes = kihd_predictors.iloc[:, genes_start:(genes_end+1)].copy()\n",
    "print(\"KIHD with genes only: {}\".format(kihd_genes.shape))\n",
    "\n",
    "# Phenotypes\n",
    "kihd_phenotypes = kihd_predictors.drop(kihd_predictors.columns.values[genes_start:genes_end+1], axis = 1)\n",
    "print(\"KIHD with phenotypes only: {}\".format(kihd_phenotypes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out predictors with more than 5% of missing values ...\n",
      "Dataset size: 2682x746\n",
      "-------------------------------------\n",
      "Filter out rows with more than 5% of missing values ...\n",
      "Dataset size: 2623x746\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Remove predictors and subjects based on the number of missing values in 'kihd_phenotypes'\n",
    "# -----------------------------------------\n",
    "# Remove variables (columns) containing more than 5% of missing values\n",
    "threshold_columns = kihd_phenotypes.shape[0]-round(0.05*kihd_phenotypes.shape[0])\n",
    "kihd_phenotypes = kihd_phenotypes.dropna(axis=1, thresh=threshold_columns) \n",
    "\n",
    "print(\"Filter out predictors with more than 5% of missing values ...\")\n",
    "print(\"Dataset size: {rows}x{cols}\".format(rows = kihd_phenotypes.shape[0], cols = kihd_phenotypes.shape[1]))\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Remove subjects (rows) with more than 5% of missing values\n",
    "threshold_rows = kihd_phenotypes.shape[1]-round(0.05*kihd_phenotypes.shape[1])\n",
    "kihd_phenotypes = kihd_phenotypes.dropna(axis=0, thresh=threshold_rows)\n",
    "\n",
    "print(\"Filter out rows with more than 5% of missing values ...\")\n",
    "print(\"Dataset size: {rows}x{cols}\".format(rows = kihd_phenotypes.shape[0], cols = kihd_phenotypes.shape[1]))\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "# Remove subjects in genes and outcomes correspondingly\n",
    "kihd_genes = kihd_genes.loc[kihd_phenotypes.index, :]\n",
    "kihd_outcomes = kihd_outcomes.loc[kihd_phenotypes.index, :]\n",
    "\n",
    "# Reset indices in all data frames after removing subjects \n",
    "kihd_genes = kihd_genes.reset_index(drop=True)\n",
    "kihd_outcomes = kihd_outcomes.reset_index(drop=True)\n",
    "kihd_phenotypes = kihd_phenotypes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/2623 with 11 missing, elapsed time: 47.254\n",
      "Imputing row 101/2623 with 29 missing, elapsed time: 47.274\n",
      "Imputing row 201/2623 with 0 missing, elapsed time: 47.283\n",
      "Imputing row 301/2623 with 1 missing, elapsed time: 47.298\n",
      "Imputing row 401/2623 with 6 missing, elapsed time: 47.306\n",
      "Imputing row 501/2623 with 0 missing, elapsed time: 47.316\n",
      "Imputing row 601/2623 with 1 missing, elapsed time: 47.324\n",
      "Imputing row 701/2623 with 0 missing, elapsed time: 47.333\n",
      "Imputing row 801/2623 with 0 missing, elapsed time: 47.341\n",
      "Imputing row 901/2623 with 0 missing, elapsed time: 47.349\n",
      "Imputing row 1001/2623 with 1 missing, elapsed time: 47.365\n",
      "Imputing row 1101/2623 with 0 missing, elapsed time: 47.373\n",
      "Imputing row 1201/2623 with 1 missing, elapsed time: 47.391\n",
      "Imputing row 1301/2623 with 6 missing, elapsed time: 47.406\n",
      "Imputing row 1401/2623 with 1 missing, elapsed time: 47.422\n",
      "Imputing row 1501/2623 with 4 missing, elapsed time: 47.448\n",
      "Imputing row 1601/2623 with 0 missing, elapsed time: 47.466\n",
      "Imputing row 1701/2623 with 0 missing, elapsed time: 47.481\n",
      "Imputing row 1801/2623 with 0 missing, elapsed time: 47.489\n",
      "Imputing row 1901/2623 with 2 missing, elapsed time: 47.498\n",
      "Imputing row 2001/2623 with 0 missing, elapsed time: 47.513\n",
      "Imputing row 2101/2623 with 0 missing, elapsed time: 47.520\n",
      "Imputing row 2201/2623 with 0 missing, elapsed time: 47.537\n",
      "Imputing row 2301/2623 with 0 missing, elapsed time: 47.562\n",
      "Imputing row 2401/2623 with 0 missing, elapsed time: 47.564\n",
      "Imputing row 2501/2623 with 3 missing, elapsed time: 47.573\n",
      "Imputing row 2601/2623 with 0 missing, elapsed time: 47.582\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Fill gaps in 'kihd_phenotypes' with kNN\n",
    "# -----------------------------------------\n",
    "\n",
    "# Scale predictors before applying the NN-based method\n",
    "scaler=MinMaxScaler().fit(kihd_phenotypes)\n",
    "kihd_phenotypes_scaled=scaler.transform(kihd_phenotypes)\n",
    "kihd_phenotypes_scaled_filled_knn = KNN(k=1).fit_transform(kihd_phenotypes_scaled)\n",
    "\n",
    "# Inverse scaling to original ranges\n",
    "kihd_phenotypes=pd.DataFrame(scaler.inverse_transform(kihd_phenotypes_scaled_filled_knn), columns=kihd_phenotypes.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Handle competing risks\n",
    "# -----------------------------------------\n",
    "# Remove subjects died because of any non-cardiovascular reason within the prediction horizon\n",
    "\n",
    "prediction_horizon = 35 * 365\n",
    "kihd_outcomes = kihd_outcomes.drop(kihd_outcomes[ (kihd_outcomes.loc[:, 'ncvd16'] == 1) & \n",
    "                                                 (kihd_outcomes.loc[:, 'ncvd16d'] <= prediction_horizon)].index, axis=0)\n",
    "# Remove subjects in kihd_genes and kihd_phenotypes correspondingly\n",
    "kihd_genes = kihd_genes.loc[kihd_outcomes.index, :]\n",
    "kihd_phenotypes = kihd_phenotypes.loc[kihd_outcomes.index, :]\n",
    "\n",
    "# Reset indices in all data frames after removing subjects \n",
    "kihd_genes = kihd_genes.reset_index(drop=True)\n",
    "kihd_outcomes = kihd_outcomes.reset_index(drop=True)\n",
    "kihd_phenotypes = kihd_phenotypes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy\n",
    "import plotly\n",
    "import os\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Perform cross-validation for the given data and model \n",
    "# -----------------------------------------\n",
    "def cv_estimator(cv_splits, data_x, data_y, model):\n",
    "    auc_test = []\n",
    "    auc_train = []\n",
    "    \n",
    "    splitting = StratifiedKFold(n_splits=cv_splits, random_state=None, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in splitting.split(np.zeros(data_y.shape[0]), data_y):\n",
    "        data_x_train, data_x_test = data_x.iloc[train_index].copy(), data_x.iloc[test_index].copy()\n",
    "        y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "        \n",
    "        #normalize\n",
    "        scaler = MinMaxScaler().fit(data_x_train)\n",
    "        data_x_train = scaler.transform(data_x_train)\n",
    "        data_x_test = scaler.transform(data_x_test)\n",
    "        #train the model\n",
    "        model.fit(data_x_train, y_train)\n",
    "        #apply to test\n",
    "        y_prob_test = [prediction[1] for prediction in model.predict_proba(data_x_test)]\n",
    "        auc_test.append(roc_auc_score(y_test, y_prob_test))\n",
    "        #apply to train\n",
    "        y_prob_train = [prediction[1] for prediction in model.predict_proba(data_x_train)]\n",
    "        auc_train.append(roc_auc_score(y_train, y_prob_train))\n",
    "        \n",
    "    return np.array(auc_train), np.array(auc_test)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Estimate a confidence interval\n",
    "# -----------------------------------------\n",
    "def CI_estimation(sample, confidence_level = 0.95):\n",
    "    degrees_freedom = sample.size - 1\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_standard_error = scipy.stats.sem(sample)\n",
    "    \n",
    "    confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
    "    #print(sample_mean, '({0:.4f}, {0:.4f})'.format(confidence_interval[0], confidence_interval[1]))\n",
    "\n",
    "    return confidence_interval\n",
    "\n",
    "# -----------------------------------------\n",
    "# Estimate AUC for the Logistic Regression model without regularization (FinRisk predictors), i.e. a baseline level\n",
    "# -----------------------------------------\n",
    "def auc_estimation_baseline(data_x, data_y, runs, cv_splits):\n",
    "    auc_test_all = []\n",
    "    auc_train_all = []\n",
    "\n",
    "    for r in range(runs):\n",
    "        model = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=100000)\n",
    "        auc_train, auc_test = cv_estimator(cv_splits, data_x, data_y, model)\n",
    "\n",
    "        auc_train_all.extend(auc_train)   \n",
    "        auc_test_all.extend(auc_test)\n",
    "            \n",
    "    return np.array(auc_train_all), np.array(auc_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an outcome variable\n",
    "outcome = 'cvd16'\n",
    "data_y = ((kihd_outcomes.loc[:, 'cvd16d'] <= prediction_horizon) & (kihd_outcomes.loc[:, 'cvd16'] == 1)).astype(\"int\").values.ravel()\n",
    "\n",
    "# Define parameters of the experiment \n",
    "runs=50\n",
    "cv_splits=5\n",
    "\n",
    "# Define the 'baseline' inputs\n",
    "data_x = kihd_phenotypes.loc[:, ['v0137', 'tup', 'mvp0224', 'bi0160', 'bi0171', 'diab', 'cvdfam']].copy()\n",
    "# Train the baseline model \n",
    "auc_train_baseline, auc_test_baseline = auc_estimation_baseline(data_x, data_y, runs, cv_splits)\n",
    "# Estimate CIs on the training and test data\n",
    "ci_test_baseline = CI_estimation(auc_test_baseline)\n",
    "ci_train_baseline = CI_estimation(auc_train_baseline)\n",
    "\n",
    "# Get mean, std, max, min for predictors\n",
    "data_x.loc[data_y == 0].describe().to_excel('predictors_healthy.xlsx')\n",
    "data_x.loc[data_y == 1].describe().to_excel('predictors_sick.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all available inputs to train the model\n",
    "data_x = kihd_phenotypes.copy()\n",
    "\n",
    "knn_neighbors = [3, 5, 10, 15, 20, 35, 50, 75, 100, 150]\n",
    "lambda_lasso = [0.025, 0.05, 0.075, 0.1, 0.15, 0.25, 0.5, 0.75, 1]\n",
    "tree_depth = [2, 3, 4, 5, 7, 9, 11, 13, 15]\n",
    "n_neurons = [3, 5, 10, 15, 30, 50, 100, 300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Estimate AUC on training, validation, and test data:\n",
    "# a model and its parameters are passed\n",
    "# a dataframe with results is returned\n",
    "# -----------------------------------------\n",
    "def auc_estimation(data_x, data_y, runs, cv_splits, model, model_name, parameter):\n",
    "    auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "\n",
    "    for r in range(runs):\n",
    "        splitting = StratifiedKFold(n_splits=cv_splits, random_state=None, shuffle=True)\n",
    "        cv = 0\n",
    "        for train_index, test_index in splitting.split(np.zeros(data_y.shape[0]), data_y):\n",
    "            data_x_train, data_x_test = data_x.loc[train_index].copy(), data_x.loc[test_index].copy()\n",
    "            y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "            \n",
    "            # -----------------------------------------\n",
    "            # Validation on the training data to choose the model parameters \n",
    "            # -----------------------------------------\n",
    "            auc_train_inside, auc_valid_inside = cv_estimator(cv_splits, data_x_train, y_train, model)\n",
    "            # -----------------------------------------\n",
    "            # -----------------------------------------\n",
    "            \n",
    "            #normalize\n",
    "            scaler = MinMaxScaler().fit(data_x_train)\n",
    "            data_x_train = scaler.transform(data_x_train)\n",
    "            data_x_test = scaler.transform(data_x_test)\n",
    "            #train the model\n",
    "            model.fit(data_x_train, y_train)\n",
    "            #apply to test\n",
    "            y_prob_test = [prediction[1] for prediction in model.predict_proba(data_x_test)]\n",
    "            auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "            #apply to train\n",
    "            y_prob_train = [prediction[1] for prediction in model.predict_proba(data_x_train)]\n",
    "            auc_train = roc_auc_score(y_train, y_prob_train)\n",
    "            \n",
    "            auc_summary = pd.concat( [auc_summary, pd.DataFrame({'run': r, 'cv': cv,\n",
    "            'auc_training': auc_train, 'auc_validation': str(list(auc_valid_inside)), 'auc_test': auc_test, \n",
    "            'model': model_name, 'parameter': parameter}, index=[0])], ignore_index=True)\n",
    "            \n",
    "            cv += 1\n",
    "              \n",
    "    return auc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for KNeighborsClassifier\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for knn in knn_neighbors:\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=knn, weights='uniform')\n",
    "    auc_summary = pd.concat([auc_summary, auc_estimation(data_x, data_y, runs, cv_splits, model_knn, 'k-Nearest Neighbors', knn)], ignore_index=True)\n",
    "    \n",
    "auc_summary.to_excel('auc_KNeighborsClassifier.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for LogisticRegression\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for lambd in lambda_lasso:\n",
    "    model_lasso = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", C=lambd)\n",
    "    auc_summary = pd.concat([auc_summary, auc_estimation(data_x, data_y, runs, cv_splits, model_lasso, 'Logistic Lasso Regression', lambd)], ignore_index=True)\n",
    "    \n",
    "auc_summary.to_excel('auc_LogisticRegression.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for DecisionTreeClassifier\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for depth in tree_depth:\n",
    "    model_dt= DecisionTreeClassifier(max_depth=depth,class_weight=None) #'balanced'\n",
    "    auc_summary = pd.concat([auc_summary, auc_estimation(data_x, data_y, runs, cv_splits, model_dt, 'Decision Tree', depth)], ignore_index=True)\n",
    "    \n",
    "auc_summary.to_excel('auc_DecisionTreeClassifier.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for RandomForestClassifier\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for depth in tree_depth:\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, max_depth=depth, bootstrap=True, oob_score=True)\n",
    "    auc_summary = pd.concat([auc_summary, auc_estimation(data_x, data_y, runs, cv_splits, model_rf, 'Random Forest', depth)], ignore_index=True)\n",
    "    \n",
    "auc_summary.to_excel('auc_RandomForestClassifier.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Run the evaluations for MLPClassifier\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "for neurons in n_neurons:\n",
    "    model_mlp = MLPClassifier(hidden_layer_sizes=(neurons, ), activation='relu', solver='adam', alpha=0.001, batch_size='auto',   ## hidden_layer_sizes=(round((inputsTrainingScaled.shape[1]+2)/2.), )\n",
    "                                                         learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=500, shuffle=True,\n",
    "                                                         random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "                                                         early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "\n",
    "    auc_summary = pd.concat([auc_summary, auc_estimation(data_x, data_y, runs, cv_splits, model_mlp, 'Multilayer Perceptron', neurons)], ignore_index=True)\n",
    "\n",
    "auc_summary.to_excel('auc_MLPClassifier.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Import the results for all the models\n",
    "# -----------------------------------------\n",
    "auc_summary = pd.DataFrame(columns = ['run', 'cv', 'auc_training', 'auc_validation', 'auc_test', 'model', 'parameter'])\n",
    "\n",
    "auc_knn = pd.read_excel('auc_KNeighborsClassifier.xlsx')\n",
    "auc_summary = pd.concat([auc_summary, auc_knn], ignore_index=True)\n",
    "\n",
    "auc_lasso = pd.read_excel('auc_LogisticRegression.xlsx')\n",
    "auc_summary = pd.concat([auc_summary, auc_lasso], ignore_index=True)\n",
    "\n",
    "auc_dt = pd.read_excel('auc_DecisionTreeClassifier.xlsx')\n",
    "auc_summary = pd.concat([auc_summary, auc_dt], ignore_index=True)\n",
    "\n",
    "auc_rf = pd.read_excel('auc_RandomForestClassifier.xlsx')\n",
    "auc_summary = pd.concat([auc_summary, auc_rf], ignore_index=True)\n",
    "\n",
    "auc_mlp = pd.read_excel('auc_MLPClassifier.xlsx')\n",
    "auc_summary = pd.concat([auc_summary, auc_mlp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Modify the results' format for drawing figures and tables\n",
    "# -----------------------------------------\n",
    "def prepare_for_boxplots(auc):\n",
    "    \n",
    "    # Boxplots\n",
    "    auc.columns = ['run', 'cv', 'training', 'validation', 'test', 'model', 'parameter']\n",
    "\n",
    "    df1 = pd.melt(auc, id_vars=['run', 'cv', 'model', 'parameter'], value_vars=['training', 'test'])\n",
    "    df1.columns = ['run', 'cv', 'model', 'parameter', 'sample', 'AUC']\n",
    "\n",
    "    for i in range(auc.shape[0]):\n",
    "        auc_valid = [float(item) for item in auc.loc[i, 'validation'][1:-1].split(', ')]\n",
    "    \n",
    "        for item in auc_valid:\n",
    "            df1 = df1.append({'run': auc.loc[i, 'run'], 'cv': auc.loc[i, 'cv'], 'model': auc.loc[i, 'model'],\n",
    "                        'parameter': auc.loc[i, 'parameter'], 'sample': 'validation', 'AUC': item},\n",
    "                         ignore_index = True)\n",
    "    \n",
    "    # Confidence intervals\n",
    "    df2 = pd.DataFrame(columns = ['mean', 'ci', 'sample', 'parameter', 'model'])\n",
    "    for prmtr in df1['parameter'].unique():\n",
    "        for smpl in ['training', 'validation', 'test']:\n",
    "            selected = (df1.loc[:, 'parameter'] == prmtr) & (df1.loc[:, 'sample'] == smpl)\n",
    "            df2 = df2.append({'mean': df1.loc[selected, 'AUC'].mean(), \n",
    "                              'ci': CI_estimation(df1.loc[selected, 'AUC'])[1] - df1.loc[selected, 'AUC'].mean(), \n",
    "                              'sample': smpl, 'parameter': prmtr, 'model': auc.loc[0, 'model']},\n",
    "                               ignore_index = True)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Apply modifications to the results\n",
    "# -----------------------------------------\n",
    "data_for_boxplots = pd.DataFrame()\n",
    "auc_stats = pd.DataFrame()\n",
    "\n",
    "auc_knn_melted, auc_knn_stats = prepare_for_boxplots(auc_knn)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_knn_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_knn_stats], ignore_index = True)\n",
    "\n",
    "auc_lasso_melted, auc_lasso_stats = prepare_for_boxplots(auc_lasso)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_lasso_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_lasso_stats], ignore_index = True)\n",
    "\n",
    "auc_dt_melted, auc_dt_stats = prepare_for_boxplots(auc_dt)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_dt_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_dt_stats], ignore_index = True)\n",
    "\n",
    "auc_rf_melted, auc_rf_stats = prepare_for_boxplots(auc_rf)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_rf_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_rf_stats], ignore_index = True)\n",
    "\n",
    "auc_mlp_melted, auc_mlp_stats = prepare_for_boxplots(auc_mlp)\n",
    "data_for_boxplots = pd.concat([data_for_boxplots, auc_mlp_melted], ignore_index = True)\n",
    "auc_stats = pd.concat([auc_stats, auc_mlp_stats], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Produce boxplots for AUCs\n",
    "# -----------------------------------------\n",
    "def draw_boxplots(data_for_boxplots):\n",
    "\n",
    "    data_for_boxplots.columns = ['run', 'cv', 'model', 'parameter', 'Sample: ', 'AUC']\n",
    "    fig = px.box(data_for_boxplots, x='parameter', y='AUC', facet_row='model', color='Sample: ', \n",
    "                 color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "    category_orders={'Sample: ': ['training', 'validation', 'test']})\n",
    "    \n",
    "    fig.update_yaxes(matches=None) \n",
    "    fig.update_xaxes(matches=None, type='category', showticklabels=True, title = '')\n",
    "\n",
    "    fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "    fig.update_traces(legendgroup = 'main')\n",
    "    \n",
    "    fig.update_layout(\n",
    "    font_size = 25,\n",
    "    autosize=True,\n",
    "    width=1700,\n",
    "    height=2500)\n",
    "    \n",
    "    \n",
    "    fig.add_scatter(x=[3, 150], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=5, col=1) \n",
    "    fig.add_scatter(x=[0.025, 1], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=4, col=1) \n",
    "    fig.add_scatter(x=[2, 15], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=3, col=1) \n",
    "    fig.add_scatter(x=[2, 15], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, showlegend = False,\n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=2, col=1) \n",
    "    fig.add_scatter(x=[3, 400], y=[auc_test_baseline.mean()]*2, marker=dict({'opacity': 0}), opacity = 0.8, \n",
    "                    line = dict({'dash': 'dash', 'color': 'gray'}), name = 'baseline test AUC', legendgroup = 'baseline',\n",
    "                    row=1, col=1) \n",
    "        \n",
    "    fig.update_layout(legend=dict( tracegroupgap = 50,\n",
    "    orientation='h', traceorder = 'grouped',\n",
    "    #yanchor='bottom', \n",
    "    bordercolor = 'gray',\n",
    "    y=0.055,\n",
    "    #xanchor='center',\n",
    "    x=0.635))\n",
    "    \n",
    "    fig.add_annotation(row=5,col=1, x=35, y=0.55, showarrow=False, text='The number of nearest neighbors')\n",
    "    fig.add_annotation(row=4,col=1, x=0.15, y=0.6, showarrow=False, text='Regularization')\n",
    "    fig.add_annotation(row=3,col=1, x=7, y=0.4, showarrow=False, text='Decision tree depth')\n",
    "    fig.add_annotation(row=2,col=1, x=7, y=0.65, showarrow=False, text='Decision tree depth')\n",
    "    fig.add_annotation(row=1,col=1, x=30, y=0.35, showarrow=False, text='The number of neurons')\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    plotly.offline.plot(fig, filename = 'AUCs.html', auto_open=False)\n",
    "    \n",
    "    \n",
    "draw_boxplots(data_for_boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# -----------------------------------------\n",
    "# Produce tables with 95%CIs for AUCs\n",
    "# -----------------------------------------\n",
    "def get_info_for_CI_table(auc_stats, model):\n",
    "    \n",
    "    selected = (auc_stats.loc[:, 'model'] == model)\n",
    "    col1 = auc_stats.loc[selected, 'parameter'].unique()\n",
    "    \n",
    "    col2 = []\n",
    "    col3 = []\n",
    "    col4 = []\n",
    "    \n",
    "    for prmtr in col1:  \n",
    "        selected_prmtr = selected & (auc_stats.loc[:, 'parameter'] == prmtr)\n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'training'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'training'), 'ci'].values[0]\n",
    "        col2.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "        \n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'validation'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'validation'), 'ci'].values[0]\n",
    "        col3.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "        \n",
    "        auc_mean = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'test'), 'mean'].values[0]\n",
    "        auc_ci = auc_stats.loc[selected_prmtr & (auc_stats.loc[:, 'sample'] == 'test'), 'ci'].values[0]\n",
    "        col4.append('{} ({}, {})'.format(round(auc_mean, 4), round(auc_mean-auc_ci, 4), round(auc_mean+auc_ci, 4)))\n",
    "    \n",
    "    return col1, col2, col3, col4\n",
    "\n",
    "\n",
    "def create_CI_tables(auc_stats):\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=5, cols=1, vertical_spacing=0.05,\n",
    "        specs=[[{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}],\n",
    "               [{\"type\": \"table\"}]],\n",
    "        subplot_titles=[\n",
    "            'k-Nearest Neighbors', \n",
    "            'Logistic Lasso Regression',\n",
    "            'Decision Tree',\n",
    "            'Random Forest',\n",
    "            'Multilayer Perceptron'])\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'k-Nearest Neighbors')\n",
    "    fig.add_trace(go.Table(header=dict(values=['The number of nearest neighbors', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 1, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Logistic Lasso Regression')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Regularization', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 2, col = 1)\n",
    "    \n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Decision Tree')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Decision tree depth', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 3, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Random Forest')\n",
    "    fig.add_trace(go.Table(header=dict(values=['Decision tree depth', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 4, col = 1)\n",
    "\n",
    "    col1, col2, col3, col4 = get_info_for_CI_table(auc_stats, 'Multilayer Perceptron')\n",
    "    fig.add_trace(go.Table(header=dict(values=['The number of neurons', 'Training data: AUC mean (95%CI)', \n",
    "                                               'Validation data: AUC mean (95%CI)', 'Test data: AUC mean (95%CI)']),\n",
    "                     cells=dict(values=[col1, col2, col3, col4])), row = 5, col = 1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "    autosize=True,\n",
    "    #width=2000,\n",
    "    height=1600)\n",
    "    fig.show()\n",
    "\n",
    "    plotly.offline.plot(fig, filename = 'CI AUCs.html', auto_open=False)\n",
    "\n",
    "    \n",
    "create_CI_tables(auc_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
